{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import tarfile  \n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence \n",
    "from keras.preprocessing.text import Tokenizer \n",
    "import re\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import  linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import  linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import laplace\n",
    "from math import log\n",
    "from random import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import binarize\n",
    "import itertools\n",
    "import random\n",
    "from scipy.optimize import minimize\n",
    "import csv\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import operator\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import log_loss\n",
    "from keras.layers.core import Dense, Dropout, Activation,Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 Keras Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 25000 training samples, 25000 test samples\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocabulary_size)\n",
    "\n",
    "print('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---review---\n",
      "[1, 2, 365, 1234, 5, 1156, 354, 11, 14, 2, 2, 7, 1016, 2, 2, 356, 44, 4, 1349, 500, 746, 5, 200, 4, 4132, 11, 2, 2, 1117, 1831, 2, 5, 4831, 26, 6, 2, 4183, 17, 369, 37, 215, 1345, 143, 2, 5, 1838, 8, 1974, 15, 36, 119, 257, 85, 52, 486, 9, 6, 2, 2, 63, 271, 6, 196, 96, 949, 4121, 4, 2, 7, 4, 2212, 2436, 819, 63, 47, 77, 2, 180, 6, 227, 11, 94, 2494, 2, 13, 423, 4, 168, 7, 4, 22, 5, 89, 665, 71, 270, 56, 5, 13, 197, 12, 161, 2, 99, 76, 23, 2, 7, 419, 665, 40, 91, 85, 108, 7, 4, 2084, 5, 4773, 81, 55, 52, 1901]\n",
      "---label---\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print('---review---')\n",
    "print(X_train[6])\n",
    "print('---label---')\n",
    "print(y_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---review with words---\n",
      "['the', 'and', 'full', 'involving', 'to', 'impressive', 'boring', 'this', 'as', 'and', 'and', 'br', 'villain', 'and', 'and', 'need', 'has', 'of', 'costumes', 'b', 'message', 'to', 'may', 'of', 'props', 'this', 'and', 'and', 'concept', 'issue', 'and', 'to', \"god's\", 'he', 'is', 'and', 'unfolds', 'movie', 'women', 'like', \"isn't\", 'surely', \"i'm\", 'and', 'to', 'toward', 'in', \"here's\", 'for', 'from', 'did', 'having', 'because', 'very', 'quality', 'it', 'is', 'and', 'and', 'really', 'book', 'is', 'both', 'too', 'worked', 'carl', 'of', 'and', 'br', 'of', 'reviewer', 'closer', 'figure', 'really', 'there', 'will', 'and', 'things', 'is', 'far', 'this', 'make', 'mistakes', 'and', 'was', \"couldn't\", 'of', 'few', 'br', 'of', 'you', 'to', \"don't\", 'female', 'than', 'place', 'she', 'to', 'was', 'between', 'that', 'nothing', 'and', 'movies', 'get', 'are', 'and', 'br', 'yes', 'female', 'just', 'its', 'because', 'many', 'br', 'of', 'overly', 'to', 'descent', 'people', 'time', 'very', 'bland']\n",
      "---label---\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word2id = imdb.get_word_index()\n",
    "id2word = {i: word for word, i in word2id.items()}\n",
    "print('---review with words---')\n",
    "print([id2word.get(i, ' ') for i in X_train[6]])\n",
    "print('---label---')\n",
    "print(y_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fawn': 34701,\n",
       " 'tsukino': 52006,\n",
       " 'nunnery': 52007,\n",
       " 'sonja': 16816,\n",
       " 'vani': 63951,\n",
       " 'woods': 1408,\n",
       " 'spiders': 16115,\n",
       " 'hanging': 2345,\n",
       " 'woody': 2289,\n",
       " 'trawling': 52008,\n",
       " \"hold's\": 52009,\n",
       " 'comically': 11307,\n",
       " 'localized': 40830,\n",
       " 'disobeying': 30568,\n",
       " \"'royale\": 52010,\n",
       " \"harpo's\": 40831,\n",
       " 'canet': 52011,\n",
       " 'aileen': 19313,\n",
       " 'acurately': 52012,\n",
       " \"diplomat's\": 52013,\n",
       " 'rickman': 25242,\n",
       " 'arranged': 6746,\n",
       " 'rumbustious': 52014,\n",
       " 'familiarness': 52015,\n",
       " \"spider'\": 52016,\n",
       " 'hahahah': 68804,\n",
       " \"wood'\": 52017,\n",
       " 'transvestism': 40833,\n",
       " \"hangin'\": 34702,\n",
       " 'bringing': 2338,\n",
       " 'seamier': 40834,\n",
       " 'wooded': 34703,\n",
       " 'bravora': 52018,\n",
       " 'grueling': 16817,\n",
       " 'wooden': 1636,\n",
       " 'wednesday': 16818,\n",
       " \"'prix\": 52019,\n",
       " 'altagracia': 34704,\n",
       " 'circuitry': 52020,\n",
       " 'crotch': 11585,\n",
       " 'busybody': 57766,\n",
       " \"tart'n'tangy\": 52021,\n",
       " 'burgade': 14129,\n",
       " 'thrace': 52023,\n",
       " \"tom's\": 11038,\n",
       " 'snuggles': 52025,\n",
       " 'francesco': 29114,\n",
       " 'complainers': 52027,\n",
       " 'templarios': 52125,\n",
       " '272': 40835,\n",
       " '273': 52028,\n",
       " 'zaniacs': 52130,\n",
       " '275': 34706,\n",
       " 'consenting': 27631,\n",
       " 'snuggled': 40836,\n",
       " 'inanimate': 15492,\n",
       " 'uality': 52030,\n",
       " 'bronte': 11926,\n",
       " 'errors': 4010,\n",
       " 'dialogs': 3230,\n",
       " \"yomada's\": 52031,\n",
       " \"madman's\": 34707,\n",
       " 'dialoge': 30585,\n",
       " 'usenet': 52033,\n",
       " 'videodrome': 40837,\n",
       " \"kid'\": 26338,\n",
       " 'pawed': 52034,\n",
       " \"'girlfriend'\": 30569,\n",
       " \"'pleasure\": 52035,\n",
       " \"'reloaded'\": 52036,\n",
       " \"kazakos'\": 40839,\n",
       " 'rocque': 52037,\n",
       " 'mailings': 52038,\n",
       " 'brainwashed': 11927,\n",
       " 'mcanally': 16819,\n",
       " \"tom''\": 52039,\n",
       " 'kurupt': 25243,\n",
       " 'affiliated': 21905,\n",
       " 'babaganoosh': 52040,\n",
       " \"noe's\": 40840,\n",
       " 'quart': 40841,\n",
       " 'kids': 359,\n",
       " 'uplifting': 5034,\n",
       " 'controversy': 7093,\n",
       " 'kida': 21906,\n",
       " 'kidd': 23379,\n",
       " \"error'\": 52041,\n",
       " 'neurologist': 52042,\n",
       " 'spotty': 18510,\n",
       " 'cobblers': 30570,\n",
       " 'projection': 9878,\n",
       " 'fastforwarding': 40842,\n",
       " 'sters': 52043,\n",
       " \"eggar's\": 52044,\n",
       " 'etherything': 52045,\n",
       " 'gateshead': 40843,\n",
       " 'airball': 34708,\n",
       " 'unsinkable': 25244,\n",
       " 'stern': 7180,\n",
       " \"cervi's\": 52046,\n",
       " 'dnd': 40844,\n",
       " 'dna': 11586,\n",
       " 'insecurity': 20598,\n",
       " \"'reboot'\": 52047,\n",
       " 'trelkovsky': 11037,\n",
       " 'jaekel': 52048,\n",
       " 'sidebars': 52049,\n",
       " \"sforza's\": 52050,\n",
       " 'distortions': 17633,\n",
       " 'mutinies': 52051,\n",
       " 'sermons': 30602,\n",
       " '7ft': 40846,\n",
       " 'boobage': 52052,\n",
       " \"o'bannon's\": 52053,\n",
       " 'populations': 23380,\n",
       " 'chulak': 52054,\n",
       " 'mesmerize': 27633,\n",
       " 'quinnell': 52055,\n",
       " 'yahoo': 10307,\n",
       " 'meteorologist': 52057,\n",
       " 'beswick': 42577,\n",
       " 'boorman': 15493,\n",
       " 'voicework': 40847,\n",
       " \"ster'\": 52058,\n",
       " 'blustering': 22922,\n",
       " 'hj': 52059,\n",
       " 'intake': 27634,\n",
       " 'morally': 5621,\n",
       " 'jumbling': 40849,\n",
       " 'bowersock': 52060,\n",
       " \"'porky's'\": 52061,\n",
       " 'gershon': 16821,\n",
       " 'ludicrosity': 40850,\n",
       " 'coprophilia': 52062,\n",
       " 'expressively': 40851,\n",
       " \"india's\": 19500,\n",
       " \"post's\": 34710,\n",
       " 'wana': 52063,\n",
       " 'wang': 5283,\n",
       " 'wand': 30571,\n",
       " 'wane': 25245,\n",
       " 'edgeways': 52321,\n",
       " 'titanium': 34711,\n",
       " 'pinta': 40852,\n",
       " 'want': 178,\n",
       " 'pinto': 30572,\n",
       " 'whoopdedoodles': 52065,\n",
       " 'tchaikovsky': 21908,\n",
       " 'travel': 2103,\n",
       " \"'victory'\": 52066,\n",
       " 'copious': 11928,\n",
       " 'gouge': 22433,\n",
       " \"chapters'\": 52067,\n",
       " 'barbra': 6702,\n",
       " 'uselessness': 30573,\n",
       " \"wan'\": 52068,\n",
       " 'assimilated': 27635,\n",
       " 'petiot': 16116,\n",
       " 'most\\x85and': 52069,\n",
       " 'dinosaurs': 3930,\n",
       " 'wrong': 352,\n",
       " 'seda': 52070,\n",
       " 'stollen': 52071,\n",
       " 'sentencing': 34712,\n",
       " 'ouroboros': 40853,\n",
       " 'assimilates': 40854,\n",
       " 'colorfully': 40855,\n",
       " 'glenne': 27636,\n",
       " 'dongen': 52072,\n",
       " 'subplots': 4760,\n",
       " 'kiloton': 52073,\n",
       " 'chandon': 23381,\n",
       " \"effect'\": 34713,\n",
       " 'snugly': 27637,\n",
       " 'kuei': 40856,\n",
       " 'welcomed': 9092,\n",
       " 'dishonor': 30071,\n",
       " 'concurrence': 52075,\n",
       " 'stoicism': 23382,\n",
       " \"guys'\": 14896,\n",
       " \"beroemd'\": 52077,\n",
       " 'butcher': 6703,\n",
       " \"melfi's\": 40857,\n",
       " 'aargh': 30623,\n",
       " 'playhouse': 20599,\n",
       " 'wickedly': 11308,\n",
       " 'fit': 1180,\n",
       " 'labratory': 52078,\n",
       " 'lifeline': 40859,\n",
       " 'screaming': 1927,\n",
       " 'fix': 4287,\n",
       " 'cineliterate': 52079,\n",
       " 'fic': 52080,\n",
       " 'fia': 52081,\n",
       " 'fig': 34714,\n",
       " 'fmvs': 52082,\n",
       " 'fie': 52083,\n",
       " 'reentered': 52084,\n",
       " 'fin': 30574,\n",
       " 'doctresses': 52085,\n",
       " 'fil': 52086,\n",
       " 'zucker': 12606,\n",
       " 'ached': 31931,\n",
       " 'counsil': 52088,\n",
       " 'paterfamilias': 52089,\n",
       " 'songwriter': 13885,\n",
       " 'shivam': 34715,\n",
       " 'hurting': 9654,\n",
       " 'effects': 299,\n",
       " 'slauther': 52090,\n",
       " \"'flame'\": 52091,\n",
       " 'sommerset': 52092,\n",
       " 'interwhined': 52093,\n",
       " 'whacking': 27638,\n",
       " 'bartok': 52094,\n",
       " 'barton': 8775,\n",
       " 'frewer': 21909,\n",
       " \"fi'\": 52095,\n",
       " 'ingrid': 6192,\n",
       " 'stribor': 30575,\n",
       " 'approporiately': 52096,\n",
       " 'wobblyhand': 52097,\n",
       " 'tantalisingly': 52098,\n",
       " 'ankylosaurus': 52099,\n",
       " 'parasites': 17634,\n",
       " 'childen': 52100,\n",
       " \"jenkins'\": 52101,\n",
       " 'metafiction': 52102,\n",
       " 'golem': 17635,\n",
       " 'indiscretion': 40860,\n",
       " \"reeves'\": 23383,\n",
       " \"inamorata's\": 57781,\n",
       " 'brittannica': 52104,\n",
       " 'adapt': 7916,\n",
       " \"russo's\": 30576,\n",
       " 'guitarists': 48246,\n",
       " 'abbott': 10553,\n",
       " 'abbots': 40861,\n",
       " 'lanisha': 17649,\n",
       " 'magickal': 40863,\n",
       " 'mattter': 52105,\n",
       " \"'willy\": 52106,\n",
       " 'pumpkins': 34716,\n",
       " 'stuntpeople': 52107,\n",
       " 'estimate': 30577,\n",
       " 'ugghhh': 40864,\n",
       " 'gameplay': 11309,\n",
       " \"wern't\": 52108,\n",
       " \"n'sync\": 40865,\n",
       " 'sickeningly': 16117,\n",
       " 'chiara': 40866,\n",
       " 'disturbed': 4011,\n",
       " 'portmanteau': 40867,\n",
       " 'ineffectively': 52109,\n",
       " \"duchonvey's\": 82143,\n",
       " \"nasty'\": 37519,\n",
       " 'purpose': 1285,\n",
       " 'lazers': 52112,\n",
       " 'lightened': 28105,\n",
       " 'kaliganj': 52113,\n",
       " 'popularism': 52114,\n",
       " \"damme's\": 18511,\n",
       " 'stylistics': 30578,\n",
       " 'mindgaming': 52115,\n",
       " 'spoilerish': 46449,\n",
       " \"'corny'\": 52117,\n",
       " 'boerner': 34718,\n",
       " 'olds': 6792,\n",
       " 'bakelite': 52118,\n",
       " 'renovated': 27639,\n",
       " 'forrester': 27640,\n",
       " \"lumiere's\": 52119,\n",
       " 'gaskets': 52024,\n",
       " 'needed': 884,\n",
       " 'smight': 34719,\n",
       " 'master': 1297,\n",
       " \"edie's\": 25905,\n",
       " 'seeber': 40868,\n",
       " 'hiya': 52120,\n",
       " 'fuzziness': 52121,\n",
       " 'genesis': 14897,\n",
       " 'rewards': 12607,\n",
       " 'enthrall': 30579,\n",
       " \"'about\": 40869,\n",
       " \"recollection's\": 52122,\n",
       " 'mutilated': 11039,\n",
       " 'fatherlands': 52123,\n",
       " \"fischer's\": 52124,\n",
       " 'positively': 5399,\n",
       " '270': 34705,\n",
       " 'ahmed': 34720,\n",
       " 'zatoichi': 9836,\n",
       " 'bannister': 13886,\n",
       " 'anniversaries': 52127,\n",
       " \"helm's\": 30580,\n",
       " \"'work'\": 52128,\n",
       " 'exclaimed': 34721,\n",
       " \"'unfunny'\": 52129,\n",
       " '274': 52029,\n",
       " 'feeling': 544,\n",
       " \"wanda's\": 52131,\n",
       " 'dolan': 33266,\n",
       " '278': 52133,\n",
       " 'peacoat': 52134,\n",
       " 'brawny': 40870,\n",
       " 'mishra': 40871,\n",
       " 'worlders': 40872,\n",
       " 'protags': 52135,\n",
       " 'skullcap': 52136,\n",
       " 'dastagir': 57596,\n",
       " 'affairs': 5622,\n",
       " 'wholesome': 7799,\n",
       " 'hymen': 52137,\n",
       " 'paramedics': 25246,\n",
       " 'unpersons': 52138,\n",
       " 'heavyarms': 52139,\n",
       " 'affaire': 52140,\n",
       " 'coulisses': 52141,\n",
       " 'hymer': 40873,\n",
       " 'kremlin': 52142,\n",
       " 'shipments': 30581,\n",
       " 'pixilated': 52143,\n",
       " \"'00s\": 30582,\n",
       " 'diminishing': 18512,\n",
       " 'cinematic': 1357,\n",
       " 'resonates': 14898,\n",
       " 'simplify': 40874,\n",
       " \"nature'\": 40875,\n",
       " 'temptresses': 40876,\n",
       " 'reverence': 16822,\n",
       " 'resonated': 19502,\n",
       " 'dailey': 34722,\n",
       " '2\\x85': 52144,\n",
       " 'treize': 27641,\n",
       " 'majo': 52145,\n",
       " 'kiya': 21910,\n",
       " 'woolnough': 52146,\n",
       " 'thanatos': 39797,\n",
       " 'sandoval': 35731,\n",
       " 'dorama': 40879,\n",
       " \"o'shaughnessy\": 52147,\n",
       " 'tech': 4988,\n",
       " 'fugitives': 32018,\n",
       " 'teck': 30583,\n",
       " \"'e'\": 76125,\n",
       " 'doesn’t': 40881,\n",
       " 'purged': 52149,\n",
       " 'saying': 657,\n",
       " \"martians'\": 41095,\n",
       " 'norliss': 23418,\n",
       " 'dickey': 27642,\n",
       " 'dicker': 52152,\n",
       " \"'sependipity\": 52153,\n",
       " 'padded': 8422,\n",
       " 'ordell': 57792,\n",
       " \"sturges'\": 40882,\n",
       " 'independentcritics': 52154,\n",
       " 'tempted': 5745,\n",
       " \"atkinson's\": 34724,\n",
       " 'hounded': 25247,\n",
       " 'apace': 52155,\n",
       " 'clicked': 15494,\n",
       " \"'humor'\": 30584,\n",
       " \"martino's\": 17177,\n",
       " \"'supporting\": 52156,\n",
       " 'warmongering': 52032,\n",
       " \"zemeckis's\": 34725,\n",
       " 'lube': 21911,\n",
       " 'shocky': 52157,\n",
       " 'plate': 7476,\n",
       " 'plata': 40883,\n",
       " 'sturgess': 40884,\n",
       " \"nerds'\": 40885,\n",
       " 'plato': 20600,\n",
       " 'plath': 34726,\n",
       " 'platt': 40886,\n",
       " 'mcnab': 52159,\n",
       " 'clumsiness': 27643,\n",
       " 'altogether': 3899,\n",
       " 'massacring': 42584,\n",
       " 'bicenntinial': 52160,\n",
       " 'skaal': 40887,\n",
       " 'droning': 14360,\n",
       " 'lds': 8776,\n",
       " 'jaguar': 21912,\n",
       " \"cale's\": 34727,\n",
       " 'nicely': 1777,\n",
       " 'mummy': 4588,\n",
       " \"lot's\": 18513,\n",
       " 'patch': 10086,\n",
       " 'kerkhof': 50202,\n",
       " \"leader's\": 52161,\n",
       " \"'movie\": 27644,\n",
       " 'uncomfirmed': 52162,\n",
       " 'heirloom': 40888,\n",
       " 'wrangle': 47360,\n",
       " 'emotion\\x85': 52163,\n",
       " \"'stargate'\": 52164,\n",
       " 'pinoy': 40889,\n",
       " 'conchatta': 40890,\n",
       " 'broeke': 41128,\n",
       " 'advisedly': 40891,\n",
       " \"barker's\": 17636,\n",
       " 'descours': 52166,\n",
       " 'lots': 772,\n",
       " 'lotr': 9259,\n",
       " 'irs': 9879,\n",
       " 'lott': 52167,\n",
       " 'xvi': 40892,\n",
       " 'irk': 34728,\n",
       " 'irl': 52168,\n",
       " 'ira': 6887,\n",
       " 'belzer': 21913,\n",
       " 'irc': 52169,\n",
       " 'ire': 27645,\n",
       " 'requisites': 40893,\n",
       " 'discipline': 7693,\n",
       " 'lyoko': 52961,\n",
       " 'extend': 11310,\n",
       " 'nature': 873,\n",
       " \"'dickie'\": 52170,\n",
       " 'optimist': 40894,\n",
       " 'lapping': 30586,\n",
       " 'superficial': 3900,\n",
       " 'vestment': 52171,\n",
       " 'extent': 2823,\n",
       " 'tendons': 52172,\n",
       " \"heller's\": 52173,\n",
       " 'quagmires': 52174,\n",
       " 'miyako': 52175,\n",
       " 'moocow': 20601,\n",
       " \"coles'\": 52176,\n",
       " 'lookit': 40895,\n",
       " 'ravenously': 52177,\n",
       " 'levitating': 40896,\n",
       " 'perfunctorily': 52178,\n",
       " 'lookin': 30587,\n",
       " \"lot'\": 40898,\n",
       " 'lookie': 52179,\n",
       " 'fearlessly': 34870,\n",
       " 'libyan': 52181,\n",
       " 'fondles': 40899,\n",
       " 'gopher': 35714,\n",
       " 'wearying': 40901,\n",
       " \"nz's\": 52182,\n",
       " 'minuses': 27646,\n",
       " 'puposelessly': 52183,\n",
       " 'shandling': 52184,\n",
       " 'decapitates': 31268,\n",
       " 'humming': 11929,\n",
       " \"'nother\": 40902,\n",
       " 'smackdown': 21914,\n",
       " 'underdone': 30588,\n",
       " 'frf': 40903,\n",
       " 'triviality': 52185,\n",
       " 'fro': 25248,\n",
       " 'bothers': 8777,\n",
       " \"'kensington\": 52186,\n",
       " 'much': 73,\n",
       " 'muco': 34730,\n",
       " 'wiseguy': 22615,\n",
       " \"richie's\": 27648,\n",
       " 'tonino': 40904,\n",
       " 'unleavened': 52187,\n",
       " 'fry': 11587,\n",
       " \"'tv'\": 40905,\n",
       " 'toning': 40906,\n",
       " 'obese': 14361,\n",
       " 'sensationalized': 30589,\n",
       " 'spiv': 40907,\n",
       " 'spit': 6259,\n",
       " 'arkin': 7364,\n",
       " 'charleton': 21915,\n",
       " 'jeon': 16823,\n",
       " 'boardroom': 21916,\n",
       " 'doubts': 4989,\n",
       " 'spin': 3084,\n",
       " 'hepo': 53083,\n",
       " 'wildcat': 27649,\n",
       " 'venoms': 10584,\n",
       " 'misconstrues': 52191,\n",
       " 'mesmerising': 18514,\n",
       " 'misconstrued': 40908,\n",
       " 'rescinds': 52192,\n",
       " 'prostrate': 52193,\n",
       " 'majid': 40909,\n",
       " 'climbed': 16479,\n",
       " 'canoeing': 34731,\n",
       " 'majin': 52195,\n",
       " 'animie': 57804,\n",
       " 'sylke': 40910,\n",
       " 'conditioned': 14899,\n",
       " 'waddell': 40911,\n",
       " '3\\x85': 52196,\n",
       " 'hyperdrive': 41188,\n",
       " 'conditioner': 34732,\n",
       " 'bricklayer': 53153,\n",
       " 'hong': 2576,\n",
       " 'memoriam': 52198,\n",
       " 'inventively': 30592,\n",
       " \"levant's\": 25249,\n",
       " 'portobello': 20638,\n",
       " 'remand': 52200,\n",
       " 'mummified': 19504,\n",
       " 'honk': 27650,\n",
       " 'spews': 19505,\n",
       " 'visitations': 40912,\n",
       " 'mummifies': 52201,\n",
       " 'cavanaugh': 25250,\n",
       " 'zeon': 23385,\n",
       " \"jungle's\": 40913,\n",
       " 'viertel': 34733,\n",
       " 'frenchmen': 27651,\n",
       " 'torpedoes': 52202,\n",
       " 'schlessinger': 52203,\n",
       " 'torpedoed': 34734,\n",
       " 'blister': 69876,\n",
       " 'cinefest': 52204,\n",
       " 'furlough': 34735,\n",
       " 'mainsequence': 52205,\n",
       " 'mentors': 40914,\n",
       " 'academic': 9094,\n",
       " 'stillness': 20602,\n",
       " 'academia': 40915,\n",
       " 'lonelier': 52206,\n",
       " 'nibby': 52207,\n",
       " \"losers'\": 52208,\n",
       " 'cineastes': 40916,\n",
       " 'corporate': 4449,\n",
       " 'massaging': 40917,\n",
       " 'bellow': 30593,\n",
       " 'absurdities': 19506,\n",
       " 'expetations': 53241,\n",
       " 'nyfiken': 40918,\n",
       " 'mehras': 75638,\n",
       " 'lasse': 52209,\n",
       " 'visability': 52210,\n",
       " 'militarily': 33946,\n",
       " \"elder'\": 52211,\n",
       " 'gainsbourg': 19023,\n",
       " 'hah': 20603,\n",
       " 'hai': 13420,\n",
       " 'haj': 34736,\n",
       " 'hak': 25251,\n",
       " 'hal': 4311,\n",
       " 'ham': 4892,\n",
       " 'duffer': 53259,\n",
       " 'haa': 52213,\n",
       " 'had': 66,\n",
       " 'advancement': 11930,\n",
       " 'hag': 16825,\n",
       " \"hand'\": 25252,\n",
       " 'hay': 13421,\n",
       " 'mcnamara': 20604,\n",
       " \"mozart's\": 52214,\n",
       " 'duffel': 30731,\n",
       " 'haq': 30594,\n",
       " 'har': 13887,\n",
       " 'has': 44,\n",
       " 'hat': 2401,\n",
       " 'hav': 40919,\n",
       " 'haw': 30595,\n",
       " 'figtings': 52215,\n",
       " 'elders': 15495,\n",
       " 'underpanted': 52216,\n",
       " 'pninson': 52217,\n",
       " 'unequivocally': 27652,\n",
       " \"barbara's\": 23673,\n",
       " \"bello'\": 52219,\n",
       " 'indicative': 12997,\n",
       " 'yawnfest': 40920,\n",
       " 'hexploitation': 52220,\n",
       " \"loder's\": 52221,\n",
       " 'sleuthing': 27653,\n",
       " \"justin's\": 32622,\n",
       " \"'ball\": 52222,\n",
       " \"'summer\": 52223,\n",
       " \"'demons'\": 34935,\n",
       " \"mormon's\": 52225,\n",
       " \"laughton's\": 34737,\n",
       " 'debell': 52226,\n",
       " 'shipyard': 39724,\n",
       " 'unabashedly': 30597,\n",
       " 'disks': 40401,\n",
       " 'crowd': 2290,\n",
       " 'crowe': 10087,\n",
       " \"vancouver's\": 56434,\n",
       " 'mosques': 34738,\n",
       " 'crown': 6627,\n",
       " 'culpas': 52227,\n",
       " 'crows': 27654,\n",
       " 'surrell': 53344,\n",
       " 'flowless': 52229,\n",
       " 'sheirk': 52230,\n",
       " \"'three\": 40923,\n",
       " \"peterson'\": 52231,\n",
       " 'ooverall': 52232,\n",
       " 'perchance': 40924,\n",
       " 'bottom': 1321,\n",
       " 'chabert': 53363,\n",
       " 'sneha': 52233,\n",
       " 'inhuman': 13888,\n",
       " 'ichii': 52234,\n",
       " 'ursla': 52235,\n",
       " 'completly': 30598,\n",
       " 'moviedom': 40925,\n",
       " 'raddick': 52236,\n",
       " 'brundage': 51995,\n",
       " 'brigades': 40926,\n",
       " 'starring': 1181,\n",
       " \"'goal'\": 52237,\n",
       " 'caskets': 52238,\n",
       " 'willcock': 52239,\n",
       " \"threesome's\": 52240,\n",
       " \"mosque'\": 52241,\n",
       " \"cover's\": 52242,\n",
       " 'spaceships': 17637,\n",
       " 'anomalous': 40927,\n",
       " 'ptsd': 27655,\n",
       " 'shirdan': 52243,\n",
       " 'obscenity': 21962,\n",
       " 'lemmings': 30599,\n",
       " 'duccio': 30600,\n",
       " \"levene's\": 52244,\n",
       " \"'gorby'\": 52245,\n",
       " \"teenager's\": 25255,\n",
       " 'marshall': 5340,\n",
       " 'honeymoon': 9095,\n",
       " 'shoots': 3231,\n",
       " 'despised': 12258,\n",
       " 'okabasho': 52246,\n",
       " 'fabric': 8289,\n",
       " 'cannavale': 18515,\n",
       " 'raped': 3537,\n",
       " \"tutt's\": 52247,\n",
       " 'grasping': 17638,\n",
       " 'despises': 18516,\n",
       " \"thief's\": 40928,\n",
       " 'rapes': 8926,\n",
       " 'raper': 52248,\n",
       " \"eyre'\": 27656,\n",
       " 'walchek': 52249,\n",
       " \"elmo's\": 23386,\n",
       " 'perfumes': 40929,\n",
       " 'spurting': 21918,\n",
       " \"exposition'\\x85\": 52250,\n",
       " 'denoting': 52251,\n",
       " 'thesaurus': 34740,\n",
       " \"shoot'\": 40930,\n",
       " 'bonejack': 49759,\n",
       " 'simpsonian': 52253,\n",
       " 'hebetude': 30601,\n",
       " \"hallow's\": 34741,\n",
       " 'desperation\\x85': 52254,\n",
       " 'incinerator': 34742,\n",
       " 'congratulations': 10308,\n",
       " 'humbled': 52255,\n",
       " \"else's\": 5924,\n",
       " 'trelkovski': 40845,\n",
       " \"rape'\": 52256,\n",
       " \"'chapters'\": 59386,\n",
       " '1600s': 52257,\n",
       " 'martian': 7253,\n",
       " 'nicest': 25256,\n",
       " 'eyred': 52259,\n",
       " 'passenger': 9457,\n",
       " 'disgrace': 6041,\n",
       " 'moderne': 52260,\n",
       " 'barrymore': 5120,\n",
       " 'yankovich': 52261,\n",
       " 'moderns': 40931,\n",
       " 'studliest': 52262,\n",
       " 'bedsheet': 52263,\n",
       " 'decapitation': 14900,\n",
       " 'slurring': 52264,\n",
       " \"'nunsploitation'\": 52265,\n",
       " \"'character'\": 34743,\n",
       " 'cambodia': 9880,\n",
       " 'rebelious': 52266,\n",
       " 'pasadena': 27657,\n",
       " 'crowne': 40932,\n",
       " \"'bedchamber\": 52267,\n",
       " 'conjectural': 52268,\n",
       " 'appologize': 52269,\n",
       " 'halfassing': 52270,\n",
       " 'paycheque': 57816,\n",
       " 'palms': 20606,\n",
       " \"'islands\": 52271,\n",
       " 'hawked': 40933,\n",
       " 'palme': 21919,\n",
       " 'conservatively': 40934,\n",
       " 'larp': 64007,\n",
       " 'palma': 5558,\n",
       " 'smelling': 21920,\n",
       " 'aragorn': 12998,\n",
       " 'hawker': 52272,\n",
       " 'hawkes': 52273,\n",
       " 'explosions': 3975,\n",
       " 'loren': 8059,\n",
       " \"pyle's\": 52274,\n",
       " 'shootout': 6704,\n",
       " \"mike's\": 18517,\n",
       " \"driscoll's\": 52275,\n",
       " 'cogsworth': 40935,\n",
       " \"britian's\": 52276,\n",
       " 'childs': 34744,\n",
       " \"portrait's\": 52277,\n",
       " 'chain': 3626,\n",
       " 'whoever': 2497,\n",
       " 'puttered': 52278,\n",
       " 'childe': 52279,\n",
       " 'maywether': 52280,\n",
       " 'chair': 3036,\n",
       " \"rance's\": 52281,\n",
       " 'machu': 34745,\n",
       " 'ballet': 4517,\n",
       " 'grapples': 34746,\n",
       " 'summerize': 76152,\n",
       " 'freelance': 30603,\n",
       " \"andrea's\": 52283,\n",
       " '\\x91very': 52284,\n",
       " 'coolidge': 45879,\n",
       " 'mache': 18518,\n",
       " 'balled': 52285,\n",
       " 'grappled': 40937,\n",
       " 'macha': 18519,\n",
       " 'underlining': 21921,\n",
       " 'macho': 5623,\n",
       " 'oversight': 19507,\n",
       " 'machi': 25257,\n",
       " 'verbally': 11311,\n",
       " 'tenacious': 21922,\n",
       " 'windshields': 40938,\n",
       " 'paychecks': 18557,\n",
       " 'jerk': 3396,\n",
       " \"good'\": 11931,\n",
       " 'prancer': 34748,\n",
       " 'prances': 21923,\n",
       " 'olympus': 52286,\n",
       " 'lark': 21924,\n",
       " 'embark': 10785,\n",
       " 'gloomy': 7365,\n",
       " 'jehaan': 52287,\n",
       " 'turaqui': 52288,\n",
       " \"child'\": 20607,\n",
       " 'locked': 2894,\n",
       " 'pranced': 52289,\n",
       " 'exact': 2588,\n",
       " 'unattuned': 52290,\n",
       " 'minute': 783,\n",
       " 'skewed': 16118,\n",
       " 'hodgins': 40940,\n",
       " 'skewer': 34749,\n",
       " 'think\\x85': 52291,\n",
       " 'rosenstein': 38765,\n",
       " 'helmit': 52292,\n",
       " 'wrestlemanias': 34750,\n",
       " 'hindered': 16826,\n",
       " \"martha's\": 30604,\n",
       " 'cheree': 52293,\n",
       " \"pluckin'\": 52294,\n",
       " 'ogles': 40941,\n",
       " 'heavyweight': 11932,\n",
       " 'aada': 82190,\n",
       " 'chopping': 11312,\n",
       " 'strongboy': 61534,\n",
       " 'hegemonic': 41342,\n",
       " 'adorns': 40942,\n",
       " 'xxth': 41346,\n",
       " 'nobuhiro': 34751,\n",
       " 'capitães': 52298,\n",
       " 'kavogianni': 52299,\n",
       " 'antwerp': 13422,\n",
       " 'celebrated': 6538,\n",
       " 'roarke': 52300,\n",
       " 'baggins': 40943,\n",
       " 'cheeseburgers': 31270,\n",
       " 'matras': 52301,\n",
       " \"nineties'\": 52302,\n",
       " \"'craig'\": 52303,\n",
       " 'celebrates': 12999,\n",
       " 'unintentionally': 3383,\n",
       " 'drafted': 14362,\n",
       " 'climby': 52304,\n",
       " '303': 52305,\n",
       " 'oldies': 18520,\n",
       " 'climbs': 9096,\n",
       " 'honour': 9655,\n",
       " 'plucking': 34752,\n",
       " '305': 30074,\n",
       " 'address': 5514,\n",
       " 'menjou': 40944,\n",
       " \"'freak'\": 42592,\n",
       " 'dwindling': 19508,\n",
       " 'benson': 9458,\n",
       " 'white’s': 52307,\n",
       " 'shamelessness': 40945,\n",
       " 'impacted': 21925,\n",
       " 'upatz': 52308,\n",
       " 'cusack': 3840,\n",
       " \"flavia's\": 37567,\n",
       " 'effette': 52309,\n",
       " 'influx': 34753,\n",
       " 'boooooooo': 52310,\n",
       " 'dimitrova': 52311,\n",
       " 'houseman': 13423,\n",
       " 'bigas': 25259,\n",
       " 'boylen': 52312,\n",
       " 'phillipenes': 52313,\n",
       " 'fakery': 40946,\n",
       " \"grandpa's\": 27658,\n",
       " 'darnell': 27659,\n",
       " 'undergone': 19509,\n",
       " 'handbags': 52315,\n",
       " 'perished': 21926,\n",
       " 'pooped': 37778,\n",
       " 'vigour': 27660,\n",
       " 'opposed': 3627,\n",
       " 'etude': 52316,\n",
       " \"caine's\": 11799,\n",
       " 'doozers': 52317,\n",
       " 'photojournals': 34754,\n",
       " 'perishes': 52318,\n",
       " 'constrains': 34755,\n",
       " 'migenes': 40948,\n",
       " 'consoled': 30605,\n",
       " 'alastair': 16827,\n",
       " 'wvs': 52319,\n",
       " 'ooooooh': 52320,\n",
       " 'approving': 34756,\n",
       " 'consoles': 40949,\n",
       " 'disparagement': 52064,\n",
       " 'futureistic': 52322,\n",
       " 'rebounding': 52323,\n",
       " \"'date\": 52324,\n",
       " 'gregoire': 52325,\n",
       " 'rutherford': 21927,\n",
       " 'americanised': 34757,\n",
       " 'novikov': 82196,\n",
       " 'following': 1042,\n",
       " 'munroe': 34758,\n",
       " \"morita'\": 52326,\n",
       " 'christenssen': 52327,\n",
       " 'oatmeal': 23106,\n",
       " 'fossey': 25260,\n",
       " 'livered': 40950,\n",
       " 'listens': 13000,\n",
       " \"'marci\": 76164,\n",
       " \"otis's\": 52330,\n",
       " 'thanking': 23387,\n",
       " 'maude': 16019,\n",
       " 'extensions': 34759,\n",
       " 'ameteurish': 52332,\n",
       " \"commender's\": 52333,\n",
       " 'agricultural': 27661,\n",
       " 'convincingly': 4518,\n",
       " 'fueled': 17639,\n",
       " 'mahattan': 54014,\n",
       " \"paris's\": 40952,\n",
       " 'vulkan': 52336,\n",
       " 'stapes': 52337,\n",
       " 'odysessy': 52338,\n",
       " 'harmon': 12259,\n",
       " 'surfing': 4252,\n",
       " 'halloran': 23494,\n",
       " 'unbelieveably': 49580,\n",
       " \"'offed'\": 52339,\n",
       " 'quadrant': 30607,\n",
       " 'inhabiting': 19510,\n",
       " 'nebbish': 34760,\n",
       " 'forebears': 40953,\n",
       " 'skirmish': 34761,\n",
       " 'ocassionally': 52340,\n",
       " \"'resist\": 52341,\n",
       " 'impactful': 21928,\n",
       " 'spicier': 52342,\n",
       " 'touristy': 40954,\n",
       " \"'football'\": 52343,\n",
       " 'webpage': 40955,\n",
       " 'exurbia': 52345,\n",
       " 'jucier': 52346,\n",
       " 'professors': 14901,\n",
       " 'structuring': 34762,\n",
       " 'jig': 30608,\n",
       " 'overlord': 40956,\n",
       " 'disconnect': 25261,\n",
       " 'sniffle': 82201,\n",
       " 'slimeball': 40957,\n",
       " 'jia': 40958,\n",
       " 'milked': 16828,\n",
       " 'banjoes': 40959,\n",
       " 'jim': 1237,\n",
       " 'workforces': 52348,\n",
       " 'jip': 52349,\n",
       " 'rotweiller': 52350,\n",
       " 'mundaneness': 34763,\n",
       " \"'ninja'\": 52351,\n",
       " \"dead'\": 11040,\n",
       " \"cipriani's\": 40960,\n",
       " 'modestly': 20608,\n",
       " \"professor'\": 52352,\n",
       " 'shacked': 40961,\n",
       " 'bashful': 34764,\n",
       " 'sorter': 23388,\n",
       " 'overpowering': 16120,\n",
       " 'workmanlike': 18521,\n",
       " 'henpecked': 27662,\n",
       " 'sorted': 18522,\n",
       " \"jōb's\": 52354,\n",
       " \"'always\": 52355,\n",
       " \"'baptists\": 34765,\n",
       " 'dreamcatchers': 52356,\n",
       " \"'silence'\": 52357,\n",
       " 'hickory': 21929,\n",
       " 'fun\\x97yet': 52358,\n",
       " 'breakumentary': 52359,\n",
       " 'didn': 15496,\n",
       " 'didi': 52360,\n",
       " 'pealing': 52361,\n",
       " 'dispite': 40962,\n",
       " \"italy's\": 25262,\n",
       " 'instability': 21930,\n",
       " 'quarter': 6539,\n",
       " 'quartet': 12608,\n",
       " 'padmé': 52362,\n",
       " \"'bleedmedry\": 52363,\n",
       " 'pahalniuk': 52364,\n",
       " 'honduras': 52365,\n",
       " 'bursting': 10786,\n",
       " \"pablo's\": 41465,\n",
       " 'irremediably': 52367,\n",
       " 'presages': 40963,\n",
       " 'bowlegged': 57832,\n",
       " 'dalip': 65183,\n",
       " 'entering': 6260,\n",
       " 'newsradio': 76172,\n",
       " 'presaged': 54150,\n",
       " \"giallo's\": 27663,\n",
       " 'bouyant': 40964,\n",
       " 'amerterish': 52368,\n",
       " 'rajni': 18523,\n",
       " 'leeves': 30610,\n",
       " 'macauley': 34767,\n",
       " 'seriously': 612,\n",
       " 'sugercoma': 52369,\n",
       " 'grimstead': 52370,\n",
       " \"'fairy'\": 52371,\n",
       " 'zenda': 30611,\n",
       " \"'twins'\": 52372,\n",
       " 'realisation': 17640,\n",
       " 'highsmith': 27664,\n",
       " 'raunchy': 7817,\n",
       " 'incentives': 40965,\n",
       " 'flatson': 52374,\n",
       " 'snooker': 35097,\n",
       " 'crazies': 16829,\n",
       " 'crazier': 14902,\n",
       " 'grandma': 7094,\n",
       " 'napunsaktha': 52375,\n",
       " 'workmanship': 30612,\n",
       " 'reisner': 52376,\n",
       " \"sanford's\": 61306,\n",
       " '\\x91doña': 52377,\n",
       " 'modest': 6108,\n",
       " \"everything's\": 19153,\n",
       " 'hamer': 40966,\n",
       " \"couldn't'\": 52379,\n",
       " 'quibble': 13001,\n",
       " 'socking': 52380,\n",
       " 'tingler': 21931,\n",
       " 'gutman': 52381,\n",
       " 'lachlan': 40967,\n",
       " 'tableaus': 52382,\n",
       " 'headbanger': 52383,\n",
       " 'spoken': 2847,\n",
       " 'cerebrally': 34768,\n",
       " \"'road\": 23490,\n",
       " 'tableaux': 21932,\n",
       " \"proust's\": 40968,\n",
       " 'periodical': 40969,\n",
       " \"shoveller's\": 52385,\n",
       " 'tamara': 25263,\n",
       " 'affords': 17641,\n",
       " 'concert': 3249,\n",
       " \"yara's\": 87955,\n",
       " 'someome': 52386,\n",
       " 'lingering': 8424,\n",
       " \"abraham's\": 41511,\n",
       " 'beesley': 34769,\n",
       " 'cherbourg': 34770,\n",
       " 'kagan': 28624,\n",
       " 'snatch': 9097,\n",
       " \"miyazaki's\": 9260,\n",
       " 'absorbs': 25264,\n",
       " \"koltai's\": 40970,\n",
       " 'tingled': 64027,\n",
       " 'crossroads': 19511,\n",
       " 'rehab': 16121,\n",
       " 'falworth': 52389,\n",
       " 'sequals': 52390,\n",
       " ...}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximumreview length: 2697\n",
      "Minimum review length: 14\n"
     ]
    }
   ],
   "source": [
    "print('Maximumreview length: {}'.format(\n",
    "    len(max((X_train+ X_test), key=len))))\n",
    "print('Minimum review length: {}'.format(\n",
    "len(min((X_test + X_test), key=len))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words = 1000\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
    "len(X_train),len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/pan/.local/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1000, 32)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_size=32\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/pan/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 24936 samples, validate on 64 samples\n",
      "Epoch 1/3\n",
      "24936/24936 [==============================] - 260s 10ms/step - loss: 0.4742 - accuracy: 0.7614 - val_loss: 0.2300 - val_accuracy: 0.9531\n",
      "Epoch 2/3\n",
      "24936/24936 [==============================] - 268s 11ms/step - loss: 0.3245 - accuracy: 0.8651 - val_loss: 0.2127 - val_accuracy: 0.9531\n",
      "Epoch 3/3\n",
      "24936/24936 [==============================] - 266s 11ms/step - loss: 0.2475 - accuracy: 0.9028 - val_loss: 0.2255 - val_accuracy: 0.9531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x217a804c88>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 3\n",
    "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
    "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n",
    "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), \n",
    "        batch_size= batch_size, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8734800219535828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30487914228439333, 0.8734800219535828]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores =model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy:', scores[1])\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 1000, 32)          160000    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               8192256   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 8,352,513\n",
      "Trainable params: 8,352,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "model_2.add(Dropout(0.2))  \n",
    "model_2.add(Flatten()) \n",
    "model_2.add(Dense(units=256,\n",
    "                activation='relu' ))\n",
    "model_2.add(Dropout(0.2))\n",
    "model_2.add(Dense(units=1,\n",
    "                activation='sigmoid' )) \n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19948 samples, validate on 4988 samples\n",
      "Epoch 1/3\n",
      " - 51s - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.7769 - val_accuracy: 0.8502\n",
      "Epoch 2/3\n",
      " - 50s - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.9122 - val_accuracy: 0.8571\n",
      "Epoch 3/3\n",
      " - 48s - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.8855 - val_accuracy: 0.8583\n"
     ]
    }
   ],
   "source": [
    "train_history =model_2.fit(X_train2, y_train2,batch_size= batch_size, \n",
    "                         epochs=num_epochs,verbose=2,\n",
    "                         validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 5s 204us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8586000204086304"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_2 = model_2.evaluate(X_test, y_test, verbose=1)\n",
    "scores_2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "probility=model_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=model_2.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 1, 0, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_classes=predict.reshape(-1)\n",
    "predict_classes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "SentimentDict={1:'POS',0:'NEG'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_test_Sentiment(i):\n",
    "    print(X_test[i])\n",
    "    print('label:',SentimentDict[y_test[i]],\n",
    "          'PREDIXTION:',SentimentDict[predict_classes[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    1   50   71   64\n",
      "  107 1653  944   44   14   20    4  936    7    2    5   94    2    5\n",
      "    4   96   36 2399    4 4338   39  406  812    8 3926  812  859   44\n",
      "    4  114   42  769   39    4  274  507  340 4948   39   14   20   11\n",
      "  192   44    4   64  183 2937  120   39    4  274   26    4 1433    7\n",
      "    4  293 1850   60   95  490 1201 2537    4    2   48    4   22 1188\n",
      "   69   93    6   52   20   60  151    2    8    4  274   13  586   28\n",
      "   77   38  685  472   36  122   24    4  114    5  769   26  801    7\n",
      "  364  352  189 1554    4  116    9 1639    5    4 3667 2048 4885  449\n",
      "  422    4   96    4    2    8   68 2121    9 1050    2   13 1408    6\n",
      "    2    7 4637    9  688   18    4 1626    2    4    2   71  307 1389\n",
      "    5   73 1319   11   68  555]\n",
      "label: NEG PREDIXTION: NEG\n"
     ]
    }
   ],
   "source": [
    "display_test_Sentiment(24000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can see dropout having the desired impact on training with a slightly slower trend in convergence and in this case a lower final accuracy. The model could probably use a few more epochs of training and may achieve a higher skill (try it an see)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 LabeledTrainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/pan/Desktop/labeledTrainData.tsv', sep='\\t')\n",
    "test = pd.read_csv('/Users/pan/Desktop/testData.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12311_10</td>\n",
       "      <td>Naturally in a film who's main themes are of m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8348_2</td>\n",
       "      <td>This movie is a disaster within a disaster fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5828_4</td>\n",
       "      <td>All in all, this is a movie for kids. We saw i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7186_2</td>\n",
       "      <td>Afraid of the Dark left me with the impression...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12128_7</td>\n",
       "      <td>A very accurate depiction of small time mob li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                             review\n",
       "0  12311_10  Naturally in a film who's main themes are of m...\n",
       "1    8348_2  This movie is a disaster within a disaster fil...\n",
       "2    5828_4  All in all, this is a movie for kids. We saw i...\n",
       "3    7186_2  Afraid of the Dark left me with the impression...\n",
       "4   12128_7  A very accurate depiction of small time mob li..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           25000\n",
       "sentiment    25000\n",
       "review       25000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        25000\n",
       "review    25000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_text(review, remove_stopwords):\n",
    "    #remove html\n",
    "    raw_text = BeautifulSoup(review, 'html.parser').get_text()\n",
    "    letters = re.sub('[^a-zA-Z]', ' ', raw_text)\n",
    "    words = letters.lower().split()\n",
    "    #remove stop words\n",
    "    if remove_stopwords:\n",
    "        all_stop_words = set(stopwords.words('english'))\n",
    "        words = [w for w in words if w not in all_stop_words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stuff going moment mj started listening music watching odd documentary watched wiz watched moonwalker maybe want get certain insight guy thought really cool eighties maybe make mind whether guilty innocent moonwalker part biography part feature film remember going see cinema originally released subtle messages mj feeling towards press also obvious message drugs bad kay visually impressive course michael jackson unless remotely like mj anyway going hate find boring may call mj egotist consenting making movie mj fans would say made fans true really nice actual feature film bit finally starts minutes excluding smooth criminal sequence joe pesci convincing psychopathic powerful drug lord wants mj dead bad beyond mj overheard plans nah joe pesci character ranted wanted people know supplying drugs etc dunno maybe hates mj music lots cool things like mj turning car robot whole speed demon sequence also director must patience saint came filming kiddy bad sequence usually directors hate working one kid let alone whole bunch performing complex dance scene bottom line movie people like mj one level another think people stay away try give wholesome message ironically mj bestest buddy movie girl michael jackson truly one talented people ever grace planet guilty well attention gave subject hmmm well know people different behind closed doors know fact either extremely nice stupid guy one sickest liars hope latter'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2 = [' '.join(review_to_text(review, True)) for review in train['review']]\n",
    "X_train_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_2 = [' '.join(review_to_text(review, True)) for review in test['review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_2 = train['sentiment']\n",
    "y_train_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_count = count_vec.fit_transform(X_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaa',\n",
       " 'aaaaaaah',\n",
       " 'aaaaah',\n",
       " 'aaaaatch',\n",
       " 'aaaahhhhhhh',\n",
       " 'aaaand',\n",
       " 'aaaarrgh',\n",
       " 'aaah',\n",
       " 'aaargh']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_count.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = tfidf_vec.fit_transform(X_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 62941)\t0.03354045373162439\n",
      "  (0, 26968)\t0.07217307173962342\n",
      "  (0, 42578)\t0.034091761849276245\n",
      "  (0, 42350)\t0.7703186447281194\n",
      "  (0, 62043)\t0.03487297244743932\n",
      "  (0, 38035)\t0.04751617903415886\n",
      "  (0, 43600)\t0.054295467513819196\n",
      "  (0, 71488)\t0.023073898100782347\n",
      "  (0, 45703)\t0.03926522998399744\n",
      "  (0, 18360)\t0.03764384002495705\n",
      "  (0, 71482)\t0.05675846026639458\n",
      "  (0, 72628)\t0.07163890269512017\n",
      "  (0, 42819)\t0.13307302119828857\n",
      "  (0, 40560)\t0.08512551931849857\n",
      "  (0, 71313)\t0.024749737549733447\n",
      "  (0, 26303)\t0.018496729631339144\n",
      "  (0, 10346)\t0.03669746300625778\n",
      "  (0, 32847)\t0.047604829337073856\n",
      "  (0, 28243)\t0.054847839906128716\n",
      "  (0, 65818)\t0.02525032488112832\n",
      "  (0, 52926)\t0.03509094232335691\n",
      "  (0, 13681)\t0.07064593076344598\n",
      "  (0, 20094)\t0.053346084856950304\n",
      "  (0, 39462)\t0.019295315365876368\n",
      "  (0, 41891)\t0.02908726933031267\n",
      "  :\t:\n",
      "  (24999, 11024)\t0.2336985200945862\n",
      "  (24999, 69731)\t0.0694608436759633\n",
      "  (24999, 56821)\t0.0789407453282018\n",
      "  (24999, 8212)\t0.10419563187936105\n",
      "  (24999, 66496)\t0.12765702217937216\n",
      "  (24999, 14829)\t0.09737592096988773\n",
      "  (24999, 40865)\t0.09289618777845667\n",
      "  (24999, 35609)\t0.09281349488722045\n",
      "  (24999, 1068)\t0.07846017144128777\n",
      "  (24999, 27650)\t0.10427216130696523\n",
      "  (24999, 64682)\t0.10681691349121074\n",
      "  (24999, 2372)\t0.11553867789106884\n",
      "  (24999, 68807)\t0.14217487881642793\n",
      "  (24999, 11148)\t0.11127402971425696\n",
      "  (24999, 23000)\t0.1344834729529056\n",
      "  (24999, 8208)\t0.11379000146648559\n",
      "  (24999, 16662)\t0.09200629977265856\n",
      "  (24999, 14778)\t0.12738720964502964\n",
      "  (24999, 16210)\t0.1543987333647921\n",
      "  (24999, 36598)\t0.15222188728065744\n",
      "  (24999, 60728)\t0.12738720964502964\n",
      "  (24999, 68690)\t0.15122262606917364\n",
      "  (24999, 33308)\t0.17252625322981072\n",
      "  (24999, 11104)\t0.37067376366906934\n",
      "  (24999, 68783)\t0.19283061917896396\n"
     ]
    }
   ],
   "source": [
    "print(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Model Prediciton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train = X_train_2[:20000]\n",
    "X1_test = X_train_2[20000:]\n",
    "y1_train = y_train_2[:20000]\n",
    "y1_test = y_train_2[20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 5000, 20000, 5000)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X1_train), len(X1_test), len(y1_train), len(y1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNB_count_Classifier():              \n",
    "    return Pipeline([\n",
    "        ('count_vec', CountVectorizer()),  \n",
    "        ('mnb', MultinomialNB())       \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('count_vec',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('mnb',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnbc_clf = MNB_count_Classifier()\n",
    "mnbc_clf.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8534"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnbc_clf.score(X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNB_tfidf_Classifier():              \n",
    "    return Pipeline([\n",
    "        ('tfidf_vec', TfidfVectorizer()),  \n",
    "        ('mnb', MultinomialNB())       \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf_vec',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('mnb',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnbt_clf = MNB_tfidf_Classifier()\n",
    "mnbt_clf.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8598"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnbt_clf.score(X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistics regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticRegression_c():              \n",
    "    return Pipeline([\n",
    "        ('count_vec', CountVectorizer()),  \n",
    "#         ('poly', PolynomialFeatures(degree=degree)),            \n",
    "        ('logistic', LogisticRegression(C=0.1, penalty='l2'))     \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('count_vec',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('logistic',\n",
       "                 LogisticRegression(C=0.1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polyc_log_reg = LogisticRegression_c()\n",
    "polyc_log_reg.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8806"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polyc_log_reg.score(X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticRegression_t():              \n",
    "    return Pipeline([\n",
    "        ('tfidf_vec', TfidfVectorizer()),  \n",
    "#         ('poly', PolynomialFeatures(degree=degree)),            \n",
    "        ('logistic', LogisticRegression(C=0.1, penalty='l2'))     \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf_vec',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('logistic',\n",
       "                 LogisticRegression(C=0.1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polyt_log_reg = LogisticRegression_t()\n",
    "polyt_log_reg.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8606"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polyt_log_reg.score(X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rbfSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RBFKernelSVC_c(gamma=1.0):\n",
    "    return Pipeline([\n",
    "        ('count_vec', CountVectorizer()),  \n",
    "        (\"svc\", SVC(kernel=\"rbf\", gamma=gamma)) \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('count_vec',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('svc',\n",
       "                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                     decision_function_shape='ovr', degree=3, gamma=1.0,\n",
       "                     kernel='rbf', max_iter=-1, probability=False,\n",
       "                     random_state=None, shrinking=True, tol=0.001,\n",
       "                     verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svcc_clf = RBFKernelSVC_c()\n",
    "svcc_clf.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.497"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svcc_clf.score(X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RBFKernelSVC_t(gamma=1.0):\n",
    "    return Pipeline([\n",
    "        ('tfidf_vec', TfidfVectorizer()),  \n",
    "        (\"svc\", SVC(kernel=\"rbf\", gamma=gamma)) \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf_vec',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('svc',\n",
       "                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                     decision_function_shape='ovr', degree=3, gamma=1.0,\n",
       "                     kernel='rbf', max_iter=-1, probability=False,\n",
       "                     random_state=None, shrinking=True, tol=0.001,\n",
       "                     verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svct_clf = RBFKernelSVC_t()\n",
    "svct_clf.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svct_clf.score(X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFC_c():\n",
    "    return Pipeline([\n",
    "        ('count_vec', CountVectorizer()),  \n",
    "        ('rfc', RandomForestClassifier(n_estimators=500, max_depth=3, random_state=666, n_jobs=-1)) \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('count_vec',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabular...\n",
       "                ('rfc',\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=3,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=500, n_jobs=-1,\n",
       "                                        oob_score=False, random_state=666,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfcc_clf = RFC_c()\n",
    "rfcc_clf.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8378"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfcc_clf.score(X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFC_t():\n",
    "    return Pipeline([\n",
    "        ('tfidf_vec', TfidfVectorizer()),  \n",
    "        ('rfc', RandomForestClassifier(n_estimators=500, max_depth=3, random_state=666, n_jobs=-1)) \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf_vec',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_patte...\n",
       "                ('rfc',\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=3,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=500, n_jobs=-1,\n",
       "                                        oob_score=False, random_state=666,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfct_clf = RFC_t()\n",
    "rfct_clf.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8308"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfct_clf.score(X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ETC_c():\n",
    "    return Pipeline([\n",
    "        ('count_vec', CountVectorizer()),  \n",
    "        ('etc', ExtraTreesClassifier(n_estimators=500, bootstrap=True, random_state=666, n_jobs=-1)) \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('count_vec',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabular...\n",
       "                ('etc',\n",
       "                 ExtraTreesClassifier(bootstrap=True, class_weight=None,\n",
       "                                      criterion='gini', max_depth=None,\n",
       "                                      max_features='auto', max_leaf_nodes=None,\n",
       "                                      min_impurity_decrease=0.0,\n",
       "                                      min_impurity_split=None,\n",
       "                                      min_samples_leaf=1, min_samples_split=2,\n",
       "                                      min_weight_fraction_leaf=0.0,\n",
       "                                      n_estimators=500, n_jobs=-1,\n",
       "                                      oob_score=False, random_state=666,\n",
       "                                      verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etc_clf = ETC_c()\n",
    "etc_clf.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.877"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etc_clf.score(X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ETC_t():\n",
    "    return Pipeline([\n",
    "        ('tfidf_vec', TfidfVectorizer()),  \n",
    "        ('etc', ExtraTreesClassifier(n_estimators=500, bootstrap=True, random_state=666, n_jobs=-1)) \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf_vec',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_patte...\n",
       "                ('etc',\n",
       "                 ExtraTreesClassifier(bootstrap=True, class_weight=None,\n",
       "                                      criterion='gini', max_depth=None,\n",
       "                                      max_features='auto', max_leaf_nodes=None,\n",
       "                                      min_impurity_decrease=0.0,\n",
       "                                      min_impurity_split=None,\n",
       "                                      min_samples_leaf=1, min_samples_split=2,\n",
       "                                      min_weight_fraction_leaf=0.0,\n",
       "                                      n_estimators=500, n_jobs=-1,\n",
       "                                      oob_score=False, random_state=666,\n",
       "                                      verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etct_clf = ETC_t()\n",
    "etct_clf.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.871"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etct_clf.score(X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ada_c():\n",
    "    return Pipeline([\n",
    "        ('count_vec', CountVectorizer()),  \n",
    "        ('adaboost', AdaBoostClassifier(DecisionTreeClassifier(max_depth=2), n_estimators=500)) \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('count_vec',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabular...\n",
       "                                    base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                                          criterion='gini',\n",
       "                                                                          max_depth=2,\n",
       "                                                                          max_features=None,\n",
       "                                                                          max_leaf_nodes=None,\n",
       "                                                                          min_impurity_decrease=0.0,\n",
       "                                                                          min_impurity_split=None,\n",
       "                                                                          min_samples_leaf=1,\n",
       "                                                                          min_samples_split=2,\n",
       "                                                                          min_weight_fraction_leaf=0.0,\n",
       "                                                                          presort=False,\n",
       "                                                                          random_state=None,\n",
       "                                                                          splitter='best'),\n",
       "                                    learning_rate=1.0, n_estimators=500,\n",
       "                                    random_state=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adac_clf = Ada_c()\n",
    "adac_clf.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8424"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adac_clf.score(X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ada_t():\n",
    "    return Pipeline([\n",
    "        ('tfidf_vec', TfidfVectorizer()),  \n",
    "        ('adaboost', AdaBoostClassifier(DecisionTreeClassifier(max_depth=2), n_estimators=500)) \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf_vec',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_patte...\n",
       "                                    base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                                          criterion='gini',\n",
       "                                                                          max_depth=2,\n",
       "                                                                          max_features=None,\n",
       "                                                                          max_leaf_nodes=None,\n",
       "                                                                          min_impurity_decrease=0.0,\n",
       "                                                                          min_impurity_split=None,\n",
       "                                                                          min_samples_leaf=1,\n",
       "                                                                          min_samples_split=2,\n",
       "                                                                          min_weight_fraction_leaf=0.0,\n",
       "                                                                          presort=False,\n",
       "                                                                          random_state=None,\n",
       "                                                                          splitter='best'),\n",
       "                                    learning_rate=1.0, n_estimators=500,\n",
       "                                    random_state=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adat_clf = Ada_t()\n",
    "adat_clf.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8334"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adat_clf.score(X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GBDT_c():\n",
    "    return Pipeline([\n",
    "        ('count_vec', CountVectorizer()),  \n",
    "        ('GBDT', GradientBoostingClassifier(max_depth=3, n_estimators=50))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('count_vec',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabular...\n",
       "                                            learning_rate=0.1, loss='deviance',\n",
       "                                            max_depth=3, max_features=None,\n",
       "                                            max_leaf_nodes=None,\n",
       "                                            min_impurity_decrease=0.0,\n",
       "                                            min_impurity_split=None,\n",
       "                                            min_samples_leaf=1,\n",
       "                                            min_samples_split=2,\n",
       "                                            min_weight_fraction_leaf=0.0,\n",
       "                                            n_estimators=50,\n",
       "                                            n_iter_no_change=None,\n",
       "                                            presort='auto', random_state=None,\n",
       "                                            subsample=1.0, tol=0.0001,\n",
       "                                            validation_fraction=0.1, verbose=0,\n",
       "                                            warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbtc_clf = GBDT_c()\n",
    "gbtc_clf.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7778"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbtc_clf.score(X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GBDT_t():\n",
    "    return Pipeline([\n",
    "        ('tfidf_vec', TfidfVectorizer()),  \n",
    "        ('GBDT', GradientBoostingClassifier(max_depth=3, n_estimators=50))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf_vec',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_patte...\n",
       "                                            learning_rate=0.1, loss='deviance',\n",
       "                                            max_depth=3, max_features=None,\n",
       "                                            max_leaf_nodes=None,\n",
       "                                            min_impurity_decrease=0.0,\n",
       "                                            min_impurity_split=None,\n",
       "                                            min_samples_leaf=1,\n",
       "                                            min_samples_split=2,\n",
       "                                            min_weight_fraction_leaf=0.0,\n",
       "                                            n_estimators=50,\n",
       "                                            n_iter_no_change=None,\n",
       "                                            presort='auto', random_state=None,\n",
       "                                            subsample=1.0, tol=0.0001,\n",
       "                                            validation_fraction=0.1, verbose=0,\n",
       "                                            warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt_clf = GBDT_t()\n",
    "gbt_clf.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.777"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt_clf.score(X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB_c():\n",
    "    return Pipeline([\n",
    "        ('count_vec', CountVectorizer()),  \n",
    "        ('XGB', xgb.XGBClassifier(n_estimators=500, max_depth=6, learning_rate=0.1,\n",
    "                                  subsample=.7, colsample_bytree=0.6, gamma=0.05))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('count_vec',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabular...\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=0.6, gamma=0.05,\n",
       "                               learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "                               min_child_weight=1, missing=None,\n",
       "                               n_estimators=500, n_jobs=1, nthread=None,\n",
       "                               objective='binary:logistic', random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               seed=None, silent=None, subsample=0.7,\n",
       "                               verbosity=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc_clf = XGB_c()\n",
    "xgbc_clf.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8634"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc_clf.score(X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB_t():\n",
    "    return Pipeline([\n",
    "        ('tfidf_vec', TfidfVectorizer()),  \n",
    "        ('XGB', xgb.XGBClassifier(n_estimators=500, max_depth=6, learning_rate=0.1,\n",
    "                                  subsample=.7, colsample_bytree=0.6, gamma=0.05))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf_vec',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_patte...\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=0.6, gamma=0.05,\n",
       "                               learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "                               min_child_weight=1, missing=None,\n",
       "                               n_estimators=500, n_jobs=1, nthread=None,\n",
       "                               objective='binary:logistic', random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               seed=None, silent=None, subsample=0.7,\n",
       "                               verbosity=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbt_clf = XGB_t()\n",
    "xgbt_clf.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8638"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbt_clf.score(X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/Users/pan/anaconda3/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /Users/pan/anaconda3/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-5dacb4a27011>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m from .callback import (early_stopping, print_evaluation, record_evaluation,\n\u001b[1;32m     10\u001b[0m                        reset_parameter)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0mcdll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLibraryLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: dlopen(/Users/pan/anaconda3/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /Users/pan/anaconda3/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_t():\n",
    "    return Pipeline([\n",
    "        ('tfidf_vec', TfidfVectorizer()),  \n",
    "        ('LGB', lgb.LGBMClassifier(n_estimators=500, max_depth=-1, colsample_bytree=0.6))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbt_clf = LGB_t()\n",
    "lgbt_clf.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbt_clf.score(X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(estimators=[\n",
    "    (\"mnb_clf\", MNB_tfidf_Classifier()),\n",
    "    (\"log_clf\", LogisticRegression_c()),\n",
    "#     (\"rfc_clf\", RFC_c()),\n",
    "    (\"etc_clf\", ETC_c()),\n",
    "    (\"xgb_clf\", XGB_t()),\n",
    "#     (\"lgb_clf\", LGB_t())\n",
    "], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('mnb_clf',\n",
       "                              Pipeline(memory=None,\n",
       "                                       steps=[('tfidf_vec',\n",
       "                                               TfidfVectorizer(analyzer='word',\n",
       "                                                               binary=False,\n",
       "                                                               decode_error='strict',\n",
       "                                                               dtype=<class 'numpy.float64'>,\n",
       "                                                               encoding='utf-8',\n",
       "                                                               input='content',\n",
       "                                                               lowercase=True,\n",
       "                                                               max_df=1.0,\n",
       "                                                               max_features=None,\n",
       "                                                               min_df=1,\n",
       "                                                               ngram_range=(1,\n",
       "                                                                            1),\n",
       "                                                               norm='l2',\n",
       "                                                               preprocessor=None,\n",
       "                                                               smooth_idf=True,\n",
       "                                                               stop_words=None,\n",
       "                                                               strip_acc...\n",
       "                                                             colsample_bytree=0.6,\n",
       "                                                             gamma=0.05,\n",
       "                                                             learning_rate=0.1,\n",
       "                                                             max_delta_step=0,\n",
       "                                                             max_depth=6,\n",
       "                                                             min_child_weight=1,\n",
       "                                                             missing=None,\n",
       "                                                             n_estimators=500,\n",
       "                                                             n_jobs=1,\n",
       "                                                             nthread=None,\n",
       "                                                             objective='binary:logistic',\n",
       "                                                             random_state=0,\n",
       "                                                             reg_alpha=0,\n",
       "                                                             reg_lambda=1,\n",
       "                                                             scale_pos_weight=1,\n",
       "                                                             seed=None,\n",
       "                                                             silent=None,\n",
       "                                                             subsample=0.7,\n",
       "                                                             verbosity=1))],\n",
       "                                       verbose=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = voting_clf.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8899324331244112"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y1_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 Using Paddlepaddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import numpy as np\n",
    "import sys\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_DIM = 2   #Number of categories for sentiment analysis\n",
    "EMB_DIM = 128     \n",
    "HID_DIM = 512  #Dimensions of hide layer   \n",
    "STACKED_NUM = 3   #LSTM Layers of the bidirectional stack\n",
    "BATCH_SIZE = 128  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_net(data, input_dim, class_dim, emb_dim, hid_dim):\n",
    "    \n",
    "    emb = fluid.layers.embedding(\n",
    "        input=data, size=[input_dim, emb_dim], is_sparse=True)\n",
    "    \n",
    "    #fluid.nets.sequence_conv_pool contains both convolution and pooling layers.\n",
    "    conv_3 = fluid.nets.sequence_conv_pool(\n",
    "        input=emb,\n",
    "        num_filters=hid_dim,\n",
    "        filter_size=3,\n",
    "        act=\"tanh\",\n",
    "        pool_type=\"sqrt\")\n",
    "    conv_4 = fluid.nets.sequence_conv_pool(\n",
    "        input=emb,\n",
    "        num_filters=hid_dim,\n",
    "        filter_size=4,\n",
    "        act=\"tanh\",\n",
    "        pool_type=\"sqrt\")\n",
    "    prediction = fluid.layers.fc(\n",
    "        input=[conv_3, conv_4], size=class_dim, act=\"softmax\")\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_lstm_net(data, input_dim, class_dim, emb_dim, hid_dim, stacked_num):\n",
    "\n",
    "    # Calculate word vector\n",
    "    emb = fluid.layers.embedding(\n",
    "        input=data, size=[input_dim, emb_dim], is_sparse=True)\n",
    "    \n",
    "    #First stack\n",
    "    #Fully connected layer\n",
    "    fc1 = fluid.layers.fc(input=emb, size=hid_dim)\n",
    "    \n",
    "    #lstm layer\n",
    "    lstm1, cell1 = fluid.layers.dynamic_lstm(input=fc1, size=hid_dim)\n",
    "\n",
    "    inputs = [fc1, lstm1]\n",
    "    \n",
    "    #All remaining stack structures\n",
    "    for i in range(2, stacked_num + 1):\n",
    "        fc = fluid.layers.fc(input=inputs, size=hid_dim)\n",
    "        lstm, cell = fluid.layers.dynamic_lstm(\n",
    "            input=fc, size=hid_dim, is_reverse=(i % 2) == 0)\n",
    "        inputs = [fc, lstm]\n",
    "    \n",
    "    #pooling layer\n",
    "    fc_last = fluid.layers.sequence_pool(input=inputs[0], pool_type='max')\n",
    "    lstm_last = fluid.layers.sequence_pool(input=inputs[1], pool_type='max')\n",
    "    \n",
    "    #Fully connected layer, softmax prediction\n",
    "    prediction = fluid.layers.fc(\n",
    "        input=[fc_last, lstm_last], size=class_dim, act='softmax')\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_program(word_dict):\n",
    "    data = fluid.layers.data(\n",
    "        name=\"words\", shape=[1], dtype=\"int64\", lod_level=1)\n",
    "\n",
    "    dict_dim = len(word_dict)\n",
    "    net = convolution_net(data, dict_dim, CLASS_DIM, EMB_DIM, HID_DIM)\n",
    "    #net = stacked_lstm_net(data, dict_dim, CLASS_DIM, EMB_DIM, HID_DIM, STACKED_NUM)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_program(prediction):\n",
    "    label = fluid.layers.data(name=\"label\", shape=[1], dtype=\"int64\")\n",
    "    cost = fluid.layers.cross_entropy(input=prediction, label=label)\n",
    "    avg_cost = fluid.layers.mean(cost)\n",
    "    accuracy = fluid.layers.accuracy(input=prediction, label=label)\n",
    "    return [avg_cost, accuracy]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_func():\n",
    "    return fluid.optimizer.Adagrad(learning_rate=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = False  \n",
    "place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading IMDB word dict....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[==================================================]b%2FaclImdb_v1.tar.gz not found, downloading https://dataset.bj.bcebos.com/imdb%2FaclImdb_v1.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading IMDB word dict....\")\n",
    "word_dict = paddle.dataset.imdb.word_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training data....\n"
     ]
    }
   ],
   "source": [
    "print (\"Reading training data....\")\n",
    "train_reader = paddle.batch(\n",
    "    paddle.reader.shuffle(\n",
    "        paddle.dataset.imdb.train(word_dict), buf_size=25000),\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading testing data....\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading testing data....\")\n",
    "test_reader = paddle.batch(\n",
    "    paddle.dataset.imdb.test(word_dict), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([inputs {\n",
       "    parameter: \"Grad\"\n",
       "    arguments: \"embedding_0.w_0@GRAD\"\n",
       "  }\n",
       "  inputs {\n",
       "    parameter: \"LearningRate\"\n",
       "    arguments: \"learning_rate_0\"\n",
       "  }\n",
       "  inputs {\n",
       "    parameter: \"Moment\"\n",
       "    arguments: \"embedding_0.w_0_moment_0\"\n",
       "  }\n",
       "  inputs {\n",
       "    parameter: \"Param\"\n",
       "    arguments: \"embedding_0.w_0\"\n",
       "  }\n",
       "  outputs {\n",
       "    parameter: \"MomentOut\"\n",
       "    arguments: \"embedding_0.w_0_moment_0\"\n",
       "  }\n",
       "  outputs {\n",
       "    parameter: \"ParamOut\"\n",
       "    arguments: \"embedding_0.w_0\"\n",
       "  }\n",
       "  type: \"adagrad\"\n",
       "  attrs {\n",
       "    name: \"op_role_var\"\n",
       "    type: STRINGS\n",
       "    strings: \"embedding_0.w_0\"\n",
       "    strings: \"embedding_0.w_0@GRAD\"\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"op_role\"\n",
       "    type: INT\n",
       "    i: 2\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"op_callstack\"\n",
       "    type: STRINGS\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/framework.py\\\", line 2459, in append_op\\n    attrs=kwargs.get(\\\"attrs\\\", None))\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 1372, in _append_optimize_op\\n    stop_gradient=True)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 433, in _create_optimization_pass\\n    param_and_grad)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 590, in apply_gradients\\n    optimize_ops = self._create_optimization_pass(params_grads)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 620, in apply_optimize\\n    optimize_ops = self.apply_gradients(params_grads)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 685, in minimize\\n    loss, startup_program=startup_program, params_grads=params_grads)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\\\", line 78, in __impl__\\n    return func(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\\\", line 25, in __impl__\\n    return wrapped_func(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"<decorator-gen-160>\\\", line 2, in minimize\\n\"\n",
       "    strings: \"  File \\\"<ipython-input-255-382c506edccf>\\\", line 5, in <module>\\n    sgd_optimizer.minimize(avg_cost)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 3267, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 3191, in run_ast_nodes\\n    if (yield from self.run_code(code, result)):\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 3020, in run_cell_async\\n    interactivity=interactivity, compiler=compiler, result=result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\\\", line 67, in _pseudo_sync_runner\\n    coro.send(None)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 2845, in _run_cell\\n    return runner(coro)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 2819, in run_cell\\n    raw_cell, store_history, silent, shell_futures)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\\\", line 536, in run_cell\\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\\\", line 294, in do_execute\\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 326, in wrapper\\n    yielded = next(result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\\\", line 534, in execute_request\\n    user_expressions, allow_stdin,\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 326, in wrapper\\n    yielded = next(result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\\\", line 267, in dispatch_shell\\n    yield gen.maybe_future(handler(stream, idents, msg))\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 326, in wrapper\\n    yielded = next(result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\\\", line 357, in process_one\\n    yield gen.maybe_future(dispatch(*args))\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 1147, in run\\n    yielded = self.gen.send(value)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 1233, in inner\\n    self.run()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py\\\", line 300, in null_wrapper\\n    return fn(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\\\", line 758, in _run_callback\\n    ret = callback()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/asyncio/events.py\\\", line 88, in _run\\n    self._context.run(self._callback, *self._args)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/asyncio/base_events.py\\\", line 1775, in _run_once\\n    handle._run()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/asyncio/base_events.py\\\", line 539, in run_forever\\n    self._run_once()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\\\", line 132, in start\\n    self.asyncio_loop.run_forever()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\\\", line 505, in start\\n    self.io_loop.start()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\\\", line 658, in launch_instance\\n    app.start()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\\\", line 16, in <module>\\n    app.launch_new_instance()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/runpy.py\\\", line 193, in _run_module_as_main\\n    \\\"__main__\\\", mod_spec)\\n\"\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"op_namescope\"\n",
       "    type: STRING\n",
       "    s: \"/optimizer/\"\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"epsilon\"\n",
       "    type: FLOAT\n",
       "    f: 9.999999974752427e-07\n",
       "  }, inputs {\n",
       "    parameter: \"Grad\"\n",
       "    arguments: \"fc_0.b_0@GRAD\"\n",
       "  }\n",
       "  inputs {\n",
       "    parameter: \"LearningRate\"\n",
       "    arguments: \"learning_rate_0\"\n",
       "  }\n",
       "  inputs {\n",
       "    parameter: \"Moment\"\n",
       "    arguments: \"fc_0.b_0_moment_0\"\n",
       "  }\n",
       "  inputs {\n",
       "    parameter: \"Param\"\n",
       "    arguments: \"fc_0.b_0\"\n",
       "  }\n",
       "  outputs {\n",
       "    parameter: \"MomentOut\"\n",
       "    arguments: \"fc_0.b_0_moment_0\"\n",
       "  }\n",
       "  outputs {\n",
       "    parameter: \"ParamOut\"\n",
       "    arguments: \"fc_0.b_0\"\n",
       "  }\n",
       "  type: \"adagrad\"\n",
       "  attrs {\n",
       "    name: \"op_role_var\"\n",
       "    type: STRINGS\n",
       "    strings: \"fc_0.b_0\"\n",
       "    strings: \"fc_0.b_0@GRAD\"\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"op_role\"\n",
       "    type: INT\n",
       "    i: 2\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"op_callstack\"\n",
       "    type: STRINGS\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/framework.py\\\", line 2459, in append_op\\n    attrs=kwargs.get(\\\"attrs\\\", None))\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 1372, in _append_optimize_op\\n    stop_gradient=True)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 433, in _create_optimization_pass\\n    param_and_grad)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 590, in apply_gradients\\n    optimize_ops = self._create_optimization_pass(params_grads)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 620, in apply_optimize\\n    optimize_ops = self.apply_gradients(params_grads)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 685, in minimize\\n    loss, startup_program=startup_program, params_grads=params_grads)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\\\", line 78, in __impl__\\n    return func(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\\\", line 25, in __impl__\\n    return wrapped_func(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"<decorator-gen-160>\\\", line 2, in minimize\\n\"\n",
       "    strings: \"  File \\\"<ipython-input-255-382c506edccf>\\\", line 5, in <module>\\n    sgd_optimizer.minimize(avg_cost)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 3267, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 3191, in run_ast_nodes\\n    if (yield from self.run_code(code, result)):\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 3020, in run_cell_async\\n    interactivity=interactivity, compiler=compiler, result=result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\\\", line 67, in _pseudo_sync_runner\\n    coro.send(None)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 2845, in _run_cell\\n    return runner(coro)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 2819, in run_cell\\n    raw_cell, store_history, silent, shell_futures)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\\\", line 536, in run_cell\\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\\\", line 294, in do_execute\\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 326, in wrapper\\n    yielded = next(result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\\\", line 534, in execute_request\\n    user_expressions, allow_stdin,\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 326, in wrapper\\n    yielded = next(result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\\\", line 267, in dispatch_shell\\n    yield gen.maybe_future(handler(stream, idents, msg))\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 326, in wrapper\\n    yielded = next(result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\\\", line 357, in process_one\\n    yield gen.maybe_future(dispatch(*args))\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 1147, in run\\n    yielded = self.gen.send(value)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 1233, in inner\\n    self.run()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py\\\", line 300, in null_wrapper\\n    return fn(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\\\", line 758, in _run_callback\\n    ret = callback()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/asyncio/events.py\\\", line 88, in _run\\n    self._context.run(self._callback, *self._args)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/asyncio/base_events.py\\\", line 1775, in _run_once\\n    handle._run()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/asyncio/base_events.py\\\", line 539, in run_forever\\n    self._run_once()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\\\", line 132, in start\\n    self.asyncio_loop.run_forever()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\\\", line 505, in start\\n    self.io_loop.start()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\\\", line 658, in launch_instance\\n    app.start()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\\\", line 16, in <module>\\n    app.launch_new_instance()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/runpy.py\\\", line 193, in _run_module_as_main\\n    \\\"__main__\\\", mod_spec)\\n\"\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"op_namescope\"\n",
       "    type: STRING\n",
       "    s: \"/optimizer_1/\"\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"epsilon\"\n",
       "    type: FLOAT\n",
       "    f: 9.999999974752427e-07\n",
       "  }, inputs {\n",
       "    parameter: \"Grad\"\n",
       "    arguments: \"fc_0.w_0@GRAD\"\n",
       "  }\n",
       "  inputs {\n",
       "    parameter: \"LearningRate\"\n",
       "    arguments: \"learning_rate_0\"\n",
       "  }\n",
       "  inputs {\n",
       "    parameter: \"Moment\"\n",
       "    arguments: \"fc_0.w_0_moment_0\"\n",
       "  }\n",
       "  inputs {\n",
       "    parameter: \"Param\"\n",
       "    arguments: \"fc_0.w_0\"\n",
       "  }\n",
       "  outputs {\n",
       "    parameter: \"MomentOut\"\n",
       "    arguments: \"fc_0.w_0_moment_0\"\n",
       "  }\n",
       "  outputs {\n",
       "    parameter: \"ParamOut\"\n",
       "    arguments: \"fc_0.w_0\"\n",
       "  }\n",
       "  type: \"adagrad\"\n",
       "  attrs {\n",
       "    name: \"op_role_var\"\n",
       "    type: STRINGS\n",
       "    strings: \"fc_0.w_0\"\n",
       "    strings: \"fc_0.w_0@GRAD\"\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"op_role\"\n",
       "    type: INT\n",
       "    i: 2\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"op_callstack\"\n",
       "    type: STRINGS\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/framework.py\\\", line 2459, in append_op\\n    attrs=kwargs.get(\\\"attrs\\\", None))\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 1372, in _append_optimize_op\\n    stop_gradient=True)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 433, in _create_optimization_pass\\n    param_and_grad)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 590, in apply_gradients\\n    optimize_ops = self._create_optimization_pass(params_grads)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 620, in apply_optimize\\n    optimize_ops = self.apply_gradients(params_grads)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 685, in minimize\\n    loss, startup_program=startup_program, params_grads=params_grads)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\\\", line 78, in __impl__\\n    return func(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\\\", line 25, in __impl__\\n    return wrapped_func(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"<decorator-gen-160>\\\", line 2, in minimize\\n\"\n",
       "    strings: \"  File \\\"<ipython-input-255-382c506edccf>\\\", line 5, in <module>\\n    sgd_optimizer.minimize(avg_cost)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 3267, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 3191, in run_ast_nodes\\n    if (yield from self.run_code(code, result)):\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 3020, in run_cell_async\\n    interactivity=interactivity, compiler=compiler, result=result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\\\", line 67, in _pseudo_sync_runner\\n    coro.send(None)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 2845, in _run_cell\\n    return runner(coro)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 2819, in run_cell\\n    raw_cell, store_history, silent, shell_futures)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\\\", line 536, in run_cell\\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\\\", line 294, in do_execute\\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 326, in wrapper\\n    yielded = next(result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\\\", line 534, in execute_request\\n    user_expressions, allow_stdin,\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 326, in wrapper\\n    yielded = next(result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\\\", line 267, in dispatch_shell\\n    yield gen.maybe_future(handler(stream, idents, msg))\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 326, in wrapper\\n    yielded = next(result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\\\", line 357, in process_one\\n    yield gen.maybe_future(dispatch(*args))\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 1147, in run\\n    yielded = self.gen.send(value)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 1233, in inner\\n    self.run()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py\\\", line 300, in null_wrapper\\n    return fn(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\\\", line 758, in _run_callback\\n    ret = callback()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/asyncio/events.py\\\", line 88, in _run\\n    self._context.run(self._callback, *self._args)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/asyncio/base_events.py\\\", line 1775, in _run_once\\n    handle._run()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/asyncio/base_events.py\\\", line 539, in run_forever\\n    self._run_once()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\\\", line 132, in start\\n    self.asyncio_loop.run_forever()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\\\", line 505, in start\\n    self.io_loop.start()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\\\", line 658, in launch_instance\\n    app.start()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\\\", line 16, in <module>\\n    app.launch_new_instance()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/runpy.py\\\", line 193, in _run_module_as_main\\n    \\\"__main__\\\", mod_spec)\\n\"\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"op_namescope\"\n",
       "    type: STRING\n",
       "    s: \"/optimizer_2/\"\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"epsilon\"\n",
       "    type: FLOAT\n",
       "    f: 9.999999974752427e-07\n",
       "  }, inputs {\n",
       "    parameter: \"Grad\"\n",
       "    arguments: \"fc_0.w_1@GRAD\"\n",
       "  }\n",
       "  inputs {\n",
       "    parameter: \"LearningRate\"\n",
       "    arguments: \"learning_rate_0\"\n",
       "  }\n",
       "  inputs {\n",
       "    parameter: \"Moment\"\n",
       "    arguments: \"fc_0.w_1_moment_0\"\n",
       "  }\n",
       "  inputs {\n",
       "    parameter: \"Param\"\n",
       "    arguments: \"fc_0.w_1\"\n",
       "  }\n",
       "  outputs {\n",
       "    parameter: \"MomentOut\"\n",
       "    arguments: \"fc_0.w_1_moment_0\"\n",
       "  }\n",
       "  outputs {\n",
       "    parameter: \"ParamOut\"\n",
       "    arguments: \"fc_0.w_1\"\n",
       "  }\n",
       "  type: \"adagrad\"\n",
       "  attrs {\n",
       "    name: \"op_role_var\"\n",
       "    type: STRINGS\n",
       "    strings: \"fc_0.w_1\"\n",
       "    strings: \"fc_0.w_1@GRAD\"\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"op_role\"\n",
       "    type: INT\n",
       "    i: 2\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"op_callstack\"\n",
       "    type: STRINGS\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/framework.py\\\", line 2459, in append_op\\n    attrs=kwargs.get(\\\"attrs\\\", None))\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 1372, in _append_optimize_op\\n    stop_gradient=True)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 433, in _create_optimization_pass\\n    param_and_grad)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 590, in apply_gradients\\n    optimize_ops = self._create_optimization_pass(params_grads)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 620, in apply_optimize\\n    optimize_ops = self.apply_gradients(params_grads)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 685, in minimize\\n    loss, startup_program=startup_program, params_grads=params_grads)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\\\", line 78, in __impl__\\n    return func(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\\\", line 25, in __impl__\\n    return wrapped_func(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"<decorator-gen-160>\\\", line 2, in minimize\\n\"\n",
       "    strings: \"  File \\\"<ipython-input-255-382c506edccf>\\\", line 5, in <module>\\n    sgd_optimizer.minimize(avg_cost)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 3267, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 3191, in run_ast_nodes\\n    if (yield from self.run_code(code, result)):\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 3020, in run_cell_async\\n    interactivity=interactivity, compiler=compiler, result=result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\\\", line 67, in _pseudo_sync_runner\\n    coro.send(None)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 2845, in _run_cell\\n    return runner(coro)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 2819, in run_cell\\n    raw_cell, store_history, silent, shell_futures)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\\\", line 536, in run_cell\\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\\\", line 294, in do_execute\\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 326, in wrapper\\n    yielded = next(result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\\\", line 534, in execute_request\\n    user_expressions, allow_stdin,\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 326, in wrapper\\n    yielded = next(result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\\\", line 267, in dispatch_shell\\n    yield gen.maybe_future(handler(stream, idents, msg))\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 326, in wrapper\\n    yielded = next(result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\\\", line 357, in process_one\\n    yield gen.maybe_future(dispatch(*args))\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 1147, in run\\n    yielded = self.gen.send(value)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 1233, in inner\\n    self.run()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py\\\", line 300, in null_wrapper\\n    return fn(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\\\", line 758, in _run_callback\\n    ret = callback()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/asyncio/events.py\\\", line 88, in _run\\n    self._context.run(self._callback, *self._args)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/asyncio/base_events.py\\\", line 1775, in _run_once\\n    handle._run()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/asyncio/base_events.py\\\", line 539, in run_forever\\n    self._run_once()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\\\", line 132, in start\\n    self.asyncio_loop.run_forever()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\\\", line 505, in start\\n    self.io_loop.start()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\\\", line 658, in launch_instance\\n    app.start()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\\\", line 16, in <module>\\n    app.launch_new_instance()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/runpy.py\\\", line 193, in _run_module_as_main\\n    \\\"__main__\\\", mod_spec)\\n\"\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"op_namescope\"\n",
       "    type: STRING\n",
       "    s: \"/optimizer_3/\"\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"epsilon\"\n",
       "    type: FLOAT\n",
       "    f: 9.999999974752427e-07\n",
       "  }, inputs {\n",
       "    parameter: \"Grad\"\n",
       "    arguments: \"sequence_conv_0.b_0@GRAD\"\n",
       "  }\n",
       "  inputs {\n",
       "    parameter: \"LearningRate\"\n",
       "    arguments: \"learning_rate_0\"\n",
       "  }\n",
       "  inputs {\n",
       "    parameter: \"Moment\"\n",
       "    arguments: \"sequence_conv_0.b_0_moment_0\"\n",
       "  }\n",
       "  inputs {\n",
       "    parameter: \"Param\"\n",
       "    arguments: \"sequence_conv_0.b_0\"\n",
       "  }\n",
       "  outputs {\n",
       "    parameter: \"MomentOut\"\n",
       "    arguments: \"sequence_conv_0.b_0_moment_0\"\n",
       "  }\n",
       "  outputs {\n",
       "    parameter: \"ParamOut\"\n",
       "    arguments: \"sequence_conv_0.b_0\"\n",
       "  }\n",
       "  type: \"adagrad\"\n",
       "  attrs {\n",
       "    name: \"op_role_var\"\n",
       "    type: STRINGS\n",
       "    strings: \"sequence_conv_0.b_0\"\n",
       "    strings: \"sequence_conv_0.b_0@GRAD\"\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"op_role\"\n",
       "    type: INT\n",
       "    i: 2\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"op_callstack\"\n",
       "    type: STRINGS\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/framework.py\\\", line 2459, in append_op\\n    attrs=kwargs.get(\\\"attrs\\\", None))\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 1372, in _append_optimize_op\\n    stop_gradient=True)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 433, in _create_optimization_pass\\n    param_and_grad)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 590, in apply_gradients\\n    optimize_ops = self._create_optimization_pass(params_grads)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 620, in apply_optimize\\n    optimize_ops = self.apply_gradients(params_grads)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 685, in minimize\\n    loss, startup_program=startup_program, params_grads=params_grads)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\\\", line 78, in __impl__\\n    return func(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\\\", line 25, in __impl__\\n    return wrapped_func(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"<decorator-gen-160>\\\", line 2, in minimize\\n\"\n",
       "    strings: \"  File \\\"<ipython-input-255-382c506edccf>\\\", line 5, in <module>\\n    sgd_optimizer.minimize(avg_cost)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 3267, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 3191, in run_ast_nodes\\n    if (yield from self.run_code(code, result)):\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 3020, in run_cell_async\\n    interactivity=interactivity, compiler=compiler, result=result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\\\", line 67, in _pseudo_sync_runner\\n    coro.send(None)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 2845, in _run_cell\\n    return runner(coro)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 2819, in run_cell\\n    raw_cell, store_history, silent, shell_futures)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\\\", line 536, in run_cell\\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\\\", line 294, in do_execute\\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 326, in wrapper\\n    yielded = next(result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\\\", line 534, in execute_request\\n    user_expressions, allow_stdin,\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 326, in wrapper\\n    yielded = next(result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\\\", line 267, in dispatch_shell\\n    yield gen.maybe_future(handler(stream, idents, msg))\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 326, in wrapper\\n    yielded = next(result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\\\", line 357, in process_one\\n    yield gen.maybe_future(dispatch(*args))\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 1147, in run\\n    yielded = self.gen.send(value)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 1233, in inner\\n    self.run()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py\\\", line 300, in null_wrapper\\n    return fn(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\\\", line 758, in _run_callback\\n    ret = callback()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/asyncio/events.py\\\", line 88, in _run\\n    self._context.run(self._callback, *self._args)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/asyncio/base_events.py\\\", line 1775, in _run_once\\n    handle._run()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/asyncio/base_events.py\\\", line 539, in run_forever\\n    self._run_once()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\\\", line 132, in start\\n    self.asyncio_loop.run_forever()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\\\", line 505, in start\\n    self.io_loop.start()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\\\", line 658, in launch_instance\\n    app.start()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\\\", line 16, in <module>\\n    app.launch_new_instance()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/runpy.py\\\", line 193, in _run_module_as_main\\n    \\\"__main__\\\", mod_spec)\\n\"\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"op_namescope\"\n",
       "    type: STRING\n",
       "    s: \"/optimizer_4/\"\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"epsilon\"\n",
       "    type: FLOAT\n",
       "    f: 9.999999974752427e-07\n",
       "  }, inputs {\n",
       "    parameter: \"Grad\"\n",
       "    arguments: \"sequence_conv_0.w_0@GRAD\"\n",
       "  }\n",
       "  inputs {\n",
       "    parameter: \"LearningRate\"\n",
       "    arguments: \"learning_rate_0\"\n",
       "  }\n",
       "  inputs {\n",
       "    parameter: \"Moment\"\n",
       "    arguments: \"sequence_conv_0.w_0_moment_0\"\n",
       "  }\n",
       "  inputs {\n",
       "    parameter: \"Param\"\n",
       "    arguments: \"sequence_conv_0.w_0\"\n",
       "  }\n",
       "  outputs {\n",
       "    parameter: \"MomentOut\"\n",
       "    arguments: \"sequence_conv_0.w_0_moment_0\"\n",
       "  }\n",
       "  outputs {\n",
       "    parameter: \"ParamOut\"\n",
       "    arguments: \"sequence_conv_0.w_0\"\n",
       "  }\n",
       "  type: \"adagrad\"\n",
       "  attrs {\n",
       "    name: \"op_role_var\"\n",
       "    type: STRINGS\n",
       "    strings: \"sequence_conv_0.w_0\"\n",
       "    strings: \"sequence_conv_0.w_0@GRAD\"\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"op_role\"\n",
       "    type: INT\n",
       "    i: 2\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"op_callstack\"\n",
       "    type: STRINGS\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/framework.py\\\", line 2459, in append_op\\n    attrs=kwargs.get(\\\"attrs\\\", None))\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 1372, in _append_optimize_op\\n    stop_gradient=True)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 433, in _create_optimization_pass\\n    param_and_grad)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 590, in apply_gradients\\n    optimize_ops = self._create_optimization_pass(params_grads)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 620, in apply_optimize\\n    optimize_ops = self.apply_gradients(params_grads)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 685, in minimize\\n    loss, startup_program=startup_program, params_grads=params_grads)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\\\", line 78, in __impl__\\n    return func(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\\\", line 25, in __impl__\\n    return wrapped_func(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"<decorator-gen-160>\\\", line 2, in minimize\\n\"\n",
       "    strings: \"  File \\\"<ipython-input-255-382c506edccf>\\\", line 5, in <module>\\n    sgd_optimizer.minimize(avg_cost)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 3267, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 3191, in run_ast_nodes\\n    if (yield from self.run_code(code, result)):\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 3020, in run_cell_async\\n    interactivity=interactivity, compiler=compiler, result=result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\\\", line 67, in _pseudo_sync_runner\\n    coro.send(None)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 2845, in _run_cell\\n    return runner(coro)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 2819, in run_cell\\n    raw_cell, store_history, silent, shell_futures)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\\\", line 536, in run_cell\\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\\\", line 294, in do_execute\\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 326, in wrapper\\n    yielded = next(result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\\\", line 534, in execute_request\\n    user_expressions, allow_stdin,\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 326, in wrapper\\n    yielded = next(result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\\\", line 267, in dispatch_shell\\n    yield gen.maybe_future(handler(stream, idents, msg))\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 326, in wrapper\\n    yielded = next(result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\\\", line 357, in process_one\\n    yield gen.maybe_future(dispatch(*args))\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 1147, in run\\n    yielded = self.gen.send(value)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 1233, in inner\\n    self.run()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py\\\", line 300, in null_wrapper\\n    return fn(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\\\", line 758, in _run_callback\\n    ret = callback()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/asyncio/events.py\\\", line 88, in _run\\n    self._context.run(self._callback, *self._args)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/asyncio/base_events.py\\\", line 1775, in _run_once\\n    handle._run()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/asyncio/base_events.py\\\", line 539, in run_forever\\n    self._run_once()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\\\", line 132, in start\\n    self.asyncio_loop.run_forever()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\\\", line 505, in start\\n    self.io_loop.start()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\\\", line 658, in launch_instance\\n    app.start()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\\\", line 16, in <module>\\n    app.launch_new_instance()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/runpy.py\\\", line 193, in _run_module_as_main\\n    \\\"__main__\\\", mod_spec)\\n\"\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"op_namescope\"\n",
       "    type: STRING\n",
       "    s: \"/optimizer_5/\"\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"epsilon\"\n",
       "    type: FLOAT\n",
       "    f: 9.999999974752427e-07\n",
       "  }, inputs {\n",
       "    parameter: \"Grad\"\n",
       "    arguments: \"sequence_conv_1.b_0@GRAD\"\n",
       "  }\n",
       "  inputs {\n",
       "    parameter: \"LearningRate\"\n",
       "    arguments: \"learning_rate_0\"\n",
       "  }\n",
       "  inputs {\n",
       "    parameter: \"Moment\"\n",
       "    arguments: \"sequence_conv_1.b_0_moment_0\"\n",
       "  }\n",
       "  inputs {\n",
       "    parameter: \"Param\"\n",
       "    arguments: \"sequence_conv_1.b_0\"\n",
       "  }\n",
       "  outputs {\n",
       "    parameter: \"MomentOut\"\n",
       "    arguments: \"sequence_conv_1.b_0_moment_0\"\n",
       "  }\n",
       "  outputs {\n",
       "    parameter: \"ParamOut\"\n",
       "    arguments: \"sequence_conv_1.b_0\"\n",
       "  }\n",
       "  type: \"adagrad\"\n",
       "  attrs {\n",
       "    name: \"op_role_var\"\n",
       "    type: STRINGS\n",
       "    strings: \"sequence_conv_1.b_0\"\n",
       "    strings: \"sequence_conv_1.b_0@GRAD\"\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"op_role\"\n",
       "    type: INT\n",
       "    i: 2\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"op_callstack\"\n",
       "    type: STRINGS\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/framework.py\\\", line 2459, in append_op\\n    attrs=kwargs.get(\\\"attrs\\\", None))\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 1372, in _append_optimize_op\\n    stop_gradient=True)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 433, in _create_optimization_pass\\n    param_and_grad)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 590, in apply_gradients\\n    optimize_ops = self._create_optimization_pass(params_grads)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 620, in apply_optimize\\n    optimize_ops = self.apply_gradients(params_grads)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 685, in minimize\\n    loss, startup_program=startup_program, params_grads=params_grads)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\\\", line 78, in __impl__\\n    return func(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\\\", line 25, in __impl__\\n    return wrapped_func(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"<decorator-gen-160>\\\", line 2, in minimize\\n\"\n",
       "    strings: \"  File \\\"<ipython-input-255-382c506edccf>\\\", line 5, in <module>\\n    sgd_optimizer.minimize(avg_cost)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 3267, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 3191, in run_ast_nodes\\n    if (yield from self.run_code(code, result)):\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 3020, in run_cell_async\\n    interactivity=interactivity, compiler=compiler, result=result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\\\", line 67, in _pseudo_sync_runner\\n    coro.send(None)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 2845, in _run_cell\\n    return runner(coro)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 2819, in run_cell\\n    raw_cell, store_history, silent, shell_futures)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\\\", line 536, in run_cell\\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\\\", line 294, in do_execute\\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 326, in wrapper\\n    yielded = next(result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\\\", line 534, in execute_request\\n    user_expressions, allow_stdin,\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 326, in wrapper\\n    yielded = next(result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\\\", line 267, in dispatch_shell\\n    yield gen.maybe_future(handler(stream, idents, msg))\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 326, in wrapper\\n    yielded = next(result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\\\", line 357, in process_one\\n    yield gen.maybe_future(dispatch(*args))\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 1147, in run\\n    yielded = self.gen.send(value)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 1233, in inner\\n    self.run()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py\\\", line 300, in null_wrapper\\n    return fn(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\\\", line 758, in _run_callback\\n    ret = callback()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/asyncio/events.py\\\", line 88, in _run\\n    self._context.run(self._callback, *self._args)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/asyncio/base_events.py\\\", line 1775, in _run_once\\n    handle._run()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/asyncio/base_events.py\\\", line 539, in run_forever\\n    self._run_once()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\\\", line 132, in start\\n    self.asyncio_loop.run_forever()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\\\", line 505, in start\\n    self.io_loop.start()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\\\", line 658, in launch_instance\\n    app.start()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\\\", line 16, in <module>\\n    app.launch_new_instance()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/runpy.py\\\", line 193, in _run_module_as_main\\n    \\\"__main__\\\", mod_spec)\\n\"\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"op_namescope\"\n",
       "    type: STRING\n",
       "    s: \"/optimizer_6/\"\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"epsilon\"\n",
       "    type: FLOAT\n",
       "    f: 9.999999974752427e-07\n",
       "  }, inputs {\n",
       "    parameter: \"Grad\"\n",
       "    arguments: \"sequence_conv_1.w_0@GRAD\"\n",
       "  }\n",
       "  inputs {\n",
       "    parameter: \"LearningRate\"\n",
       "    arguments: \"learning_rate_0\"\n",
       "  }\n",
       "  inputs {\n",
       "    parameter: \"Moment\"\n",
       "    arguments: \"sequence_conv_1.w_0_moment_0\"\n",
       "  }\n",
       "  inputs {\n",
       "    parameter: \"Param\"\n",
       "    arguments: \"sequence_conv_1.w_0\"\n",
       "  }\n",
       "  outputs {\n",
       "    parameter: \"MomentOut\"\n",
       "    arguments: \"sequence_conv_1.w_0_moment_0\"\n",
       "  }\n",
       "  outputs {\n",
       "    parameter: \"ParamOut\"\n",
       "    arguments: \"sequence_conv_1.w_0\"\n",
       "  }\n",
       "  type: \"adagrad\"\n",
       "  attrs {\n",
       "    name: \"op_role_var\"\n",
       "    type: STRINGS\n",
       "    strings: \"sequence_conv_1.w_0\"\n",
       "    strings: \"sequence_conv_1.w_0@GRAD\"\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"op_role\"\n",
       "    type: INT\n",
       "    i: 2\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"op_callstack\"\n",
       "    type: STRINGS\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/framework.py\\\", line 2459, in append_op\\n    attrs=kwargs.get(\\\"attrs\\\", None))\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 1372, in _append_optimize_op\\n    stop_gradient=True)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 433, in _create_optimization_pass\\n    param_and_grad)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 590, in apply_gradients\\n    optimize_ops = self._create_optimization_pass(params_grads)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 620, in apply_optimize\\n    optimize_ops = self.apply_gradients(params_grads)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/optimizer.py\\\", line 685, in minimize\\n    loss, startup_program=startup_program, params_grads=params_grads)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\\\", line 78, in __impl__\\n    return func(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\\\", line 25, in __impl__\\n    return wrapped_func(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"<decorator-gen-160>\\\", line 2, in minimize\\n\"\n",
       "    strings: \"  File \\\"<ipython-input-255-382c506edccf>\\\", line 5, in <module>\\n    sgd_optimizer.minimize(avg_cost)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 3267, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 3191, in run_ast_nodes\\n    if (yield from self.run_code(code, result)):\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 3020, in run_cell_async\\n    interactivity=interactivity, compiler=compiler, result=result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\\\", line 67, in _pseudo_sync_runner\\n    coro.send(None)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 2845, in _run_cell\\n    return runner(coro)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\\\", line 2819, in run_cell\\n    raw_cell, store_history, silent, shell_futures)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\\\", line 536, in run_cell\\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\\\", line 294, in do_execute\\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 326, in wrapper\\n    yielded = next(result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\\\", line 534, in execute_request\\n    user_expressions, allow_stdin,\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 326, in wrapper\\n    yielded = next(result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\\\", line 267, in dispatch_shell\\n    yield gen.maybe_future(handler(stream, idents, msg))\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 326, in wrapper\\n    yielded = next(result)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\\\", line 357, in process_one\\n    yield gen.maybe_future(dispatch(*args))\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 1147, in run\\n    yielded = self.gen.send(value)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/gen.py\\\", line 1233, in inner\\n    self.run()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py\\\", line 300, in null_wrapper\\n    return fn(*args, **kwargs)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\\\", line 758, in _run_callback\\n    ret = callback()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/asyncio/events.py\\\", line 88, in _run\\n    self._context.run(self._callback, *self._args)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/asyncio/base_events.py\\\", line 1775, in _run_once\\n    handle._run()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/asyncio/base_events.py\\\", line 539, in run_forever\\n    self._run_once()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\\\", line 132, in start\\n    self.asyncio_loop.run_forever()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\\\", line 505, in start\\n    self.io_loop.start()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\\\", line 658, in launch_instance\\n    app.start()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\\\", line 16, in <module>\\n    app.launch_new_instance()\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n\"\n",
       "    strings: \"  File \\\"/Users/pan/anaconda3/lib/python3.7/runpy.py\\\", line 193, in _run_module_as_main\\n    \\\"__main__\\\", mod_spec)\\n\"\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"op_namescope\"\n",
       "    type: STRING\n",
       "    s: \"/optimizer_7/\"\n",
       "  }\n",
       "  attrs {\n",
       "    name: \"epsilon\"\n",
       "    type: FLOAT\n",
       "    f: 9.999999974752427e-07\n",
       "  }], [(name: \"embedding_0.w_0\"\n",
       "   type {\n",
       "     type: LOD_TENSOR\n",
       "     lod_tensor {\n",
       "       tensor {\n",
       "         data_type: FP32\n",
       "         dims: 5147\n",
       "         dims: 128\n",
       "       }\n",
       "     }\n",
       "   }\n",
       "   persistable: true, name: \"embedding_0.w_0@GRAD\"\n",
       "   type {\n",
       "     type: SELECTED_ROWS\n",
       "     selected_rows {\n",
       "       data_type: FP32\n",
       "       dims: 5147\n",
       "       dims: 128\n",
       "     }\n",
       "   }), (name: \"sequence_conv_0.w_0\"\n",
       "   type {\n",
       "     type: LOD_TENSOR\n",
       "     lod_tensor {\n",
       "       tensor {\n",
       "         data_type: FP32\n",
       "         dims: 384\n",
       "         dims: 512\n",
       "       }\n",
       "     }\n",
       "   }\n",
       "   persistable: true, name: \"sequence_conv_0.w_0@GRAD\"\n",
       "   type {\n",
       "     type: LOD_TENSOR\n",
       "     lod_tensor {\n",
       "       tensor {\n",
       "         data_type: FP32\n",
       "         dims: 384\n",
       "         dims: 512\n",
       "       }\n",
       "     }\n",
       "   }), (name: \"sequence_conv_0.b_0\"\n",
       "   type {\n",
       "     type: LOD_TENSOR\n",
       "     lod_tensor {\n",
       "       tensor {\n",
       "         data_type: FP32\n",
       "         dims: 512\n",
       "       }\n",
       "     }\n",
       "   }\n",
       "   persistable: true, name: \"sequence_conv_0.b_0@GRAD\"\n",
       "   type {\n",
       "     type: LOD_TENSOR\n",
       "     lod_tensor {\n",
       "       tensor {\n",
       "         data_type: FP32\n",
       "         dims: 512\n",
       "       }\n",
       "       lod_level: 0\n",
       "     }\n",
       "   }), (name: \"sequence_conv_1.w_0\"\n",
       "   type {\n",
       "     type: LOD_TENSOR\n",
       "     lod_tensor {\n",
       "       tensor {\n",
       "         data_type: FP32\n",
       "         dims: 512\n",
       "         dims: 512\n",
       "       }\n",
       "     }\n",
       "   }\n",
       "   persistable: true, name: \"sequence_conv_1.w_0@GRAD\"\n",
       "   type {\n",
       "     type: LOD_TENSOR\n",
       "     lod_tensor {\n",
       "       tensor {\n",
       "         data_type: FP32\n",
       "         dims: 512\n",
       "         dims: 512\n",
       "       }\n",
       "     }\n",
       "   }), (name: \"sequence_conv_1.b_0\"\n",
       "   type {\n",
       "     type: LOD_TENSOR\n",
       "     lod_tensor {\n",
       "       tensor {\n",
       "         data_type: FP32\n",
       "         dims: 512\n",
       "       }\n",
       "     }\n",
       "   }\n",
       "   persistable: true, name: \"sequence_conv_1.b_0@GRAD\"\n",
       "   type {\n",
       "     type: LOD_TENSOR\n",
       "     lod_tensor {\n",
       "       tensor {\n",
       "         data_type: FP32\n",
       "         dims: 512\n",
       "       }\n",
       "       lod_level: 0\n",
       "     }\n",
       "   }), (name: \"fc_0.w_0\"\n",
       "   type {\n",
       "     type: LOD_TENSOR\n",
       "     lod_tensor {\n",
       "       tensor {\n",
       "         data_type: FP32\n",
       "         dims: 512\n",
       "         dims: 2\n",
       "       }\n",
       "     }\n",
       "   }\n",
       "   persistable: true, name: \"fc_0.w_0@GRAD\"\n",
       "   type {\n",
       "     type: LOD_TENSOR\n",
       "     lod_tensor {\n",
       "       tensor {\n",
       "         data_type: FP32\n",
       "         dims: 512\n",
       "         dims: 2\n",
       "       }\n",
       "     }\n",
       "   }), (name: \"fc_0.w_1\"\n",
       "   type {\n",
       "     type: LOD_TENSOR\n",
       "     lod_tensor {\n",
       "       tensor {\n",
       "         data_type: FP32\n",
       "         dims: 512\n",
       "         dims: 2\n",
       "       }\n",
       "     }\n",
       "   }\n",
       "   persistable: true, name: \"fc_0.w_1@GRAD\"\n",
       "   type {\n",
       "     type: LOD_TENSOR\n",
       "     lod_tensor {\n",
       "       tensor {\n",
       "         data_type: FP32\n",
       "         dims: 512\n",
       "         dims: 2\n",
       "       }\n",
       "     }\n",
       "   }), (name: \"fc_0.b_0\"\n",
       "   type {\n",
       "     type: LOD_TENSOR\n",
       "     lod_tensor {\n",
       "       tensor {\n",
       "         data_type: FP32\n",
       "         dims: 2\n",
       "       }\n",
       "     }\n",
       "   }\n",
       "   persistable: true, name: \"fc_0.b_0@GRAD\"\n",
       "   type {\n",
       "     type: LOD_TENSOR\n",
       "     lod_tensor {\n",
       "       tensor {\n",
       "         data_type: FP32\n",
       "         dims: 2\n",
       "       }\n",
       "       lod_level: 0\n",
       "     }\n",
       "   })])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exe = fluid.Executor(place)\n",
    "prediction = inference_program(word_dict)\n",
    "[avg_cost, accuracy] = train_program(prediction)\n",
    "sgd_optimizer = optimizer_func()\n",
    "sgd_optimizer.minimize(avg_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the result of the model on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(program, reader):\n",
    "    count = 0\n",
    "    feed_var_list = [\n",
    "        program.global_block().var(var_name) for var_name in feed_order\n",
    "    ]\n",
    "    feeder_test = fluid.DataFeeder(feed_list=feed_var_list, place=place)\n",
    "    test_exe = fluid.Executor(place)\n",
    "    accumulated = len([avg_cost, accuracy]) * [0]\n",
    "    for test_data in reader():\n",
    "        avg_cost_np = test_exe.run(\n",
    "            program=program,\n",
    "            feed=feeder_test.feed(test_data),\n",
    "            fetch_list=[avg_cost, accuracy])\n",
    "        accumulated = [\n",
    "            x[0] + x[1][0] for x in zip(accumulated, avg_cost_np)\n",
    "        ]\n",
    "        count += 1\n",
    "    return [x / count for x in accumulated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dirname = \"understand_sentiment_conv.inference.model\"\n",
    "feed_order = ['words', 'label']\n",
    "pass_num = 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(main_program):  \n",
    "    exe.run(fluid.default_startup_program())\n",
    "    feed_var_list_loop = [\n",
    "        main_program.global_block().var(var_name) for var_name in feed_order\n",
    "    ]\n",
    "    feeder = fluid.DataFeeder(\n",
    "        feed_list=feed_var_list_loop, place=place)\n",
    "\n",
    "    test_program = fluid.default_main_program().clone(for_test=True)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch_id in range(pass_num):\n",
    "        for step_id, data in enumerate(train_reader()):\n",
    "            metrics = exe.run(main_program,\n",
    "                              feed=feeder.feed(data),\n",
    "                              fetch_list=[avg_cost, accuracy])\n",
    "         \n",
    "            # Testing Results\n",
    "            avg_cost_test, acc_test = train_test(test_program, test_reader)\n",
    "            print('Step {0}, Test Loss {1:0.2}, Acc {2:0.2}'.format(\n",
    "                step_id, avg_cost_test, acc_test))\n",
    "\n",
    "            print(\"Step {0}, Epoch {1} Metrics {2}\".format(\n",
    "                step_id, epoch_id, list(map(np.array,\n",
    "                                            metrics))))\n",
    "            if step_id == 30:\n",
    "                if params_dirname is not None:\n",
    "                    fluid.io.save_inference_model(params_dirname, [\"words\"],\n",
    "                                                  prediction, exe)\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Test Loss 2.1, Acc 0.5\n",
      "Step 0, Epoch 0 Metrics [array([0.697872], dtype=float32), array([0.4609375], dtype=float32)]\n",
      "Step 1, Test Loss 0.74, Acc 0.5\n",
      "Step 1, Epoch 0 Metrics [array([2.253068], dtype=float32), array([0.453125], dtype=float32)]\n",
      "Step 2, Test Loss 0.77, Acc 0.5\n",
      "Step 2, Epoch 0 Metrics [array([0.7364794], dtype=float32), array([0.4921875], dtype=float32)]\n",
      "Step 3, Test Loss 0.75, Acc 0.51\n",
      "Step 3, Epoch 0 Metrics [array([0.7874141], dtype=float32), array([0.4921875], dtype=float32)]\n",
      "Step 4, Test Loss 0.74, Acc 0.5\n",
      "Step 4, Epoch 0 Metrics [array([0.79995894], dtype=float32), array([0.453125], dtype=float32)]\n",
      "Step 5, Test Loss 0.65, Acc 0.63\n",
      "Step 5, Epoch 0 Metrics [array([0.70945644], dtype=float32), array([0.53125], dtype=float32)]\n",
      "Step 6, Test Loss 0.65, Acc 0.59\n",
      "Step 6, Epoch 0 Metrics [array([0.64539003], dtype=float32), array([0.65625], dtype=float32)]\n",
      "Step 7, Test Loss 0.65, Acc 0.65\n",
      "Step 7, Epoch 0 Metrics [array([0.65699106], dtype=float32), array([0.6171875], dtype=float32)]\n",
      "Step 8, Test Loss 0.63, Acc 0.64\n",
      "Step 8, Epoch 0 Metrics [array([0.6213407], dtype=float32), array([0.640625], dtype=float32)]\n",
      "Step 9, Test Loss 0.62, Acc 0.68\n",
      "Step 9, Epoch 0 Metrics [array([0.60490876], dtype=float32), array([0.7265625], dtype=float32)]\n",
      "Step 10, Test Loss 0.61, Acc 0.67\n",
      "Step 10, Epoch 0 Metrics [array([0.6059818], dtype=float32), array([0.734375], dtype=float32)]\n",
      "Step 11, Test Loss 0.61, Acc 0.64\n",
      "Step 11, Epoch 0 Metrics [array([0.62263006], dtype=float32), array([0.640625], dtype=float32)]\n",
      "Step 12, Test Loss 0.61, Acc 0.7\n",
      "Step 12, Epoch 0 Metrics [array([0.6381704], dtype=float32), array([0.6015625], dtype=float32)]\n",
      "Step 13, Test Loss 0.62, Acc 0.61\n",
      "Step 13, Epoch 0 Metrics [array([0.60530543], dtype=float32), array([0.734375], dtype=float32)]\n",
      "Step 14, Test Loss 0.66, Acc 0.62\n",
      "Step 14, Epoch 0 Metrics [array([0.62055254], dtype=float32), array([0.6328125], dtype=float32)]\n",
      "Step 15, Test Loss 0.56, Acc 0.75\n",
      "Step 15, Epoch 0 Metrics [array([0.58520037], dtype=float32), array([0.6640625], dtype=float32)]\n",
      "Step 16, Test Loss 0.55, Acc 0.78\n",
      "Step 16, Epoch 0 Metrics [array([0.6182339], dtype=float32), array([0.6640625], dtype=float32)]\n",
      "Step 17, Test Loss 0.55, Acc 0.76\n",
      "Step 17, Epoch 0 Metrics [array([0.5579487], dtype=float32), array([0.765625], dtype=float32)]\n",
      "Step 18, Test Loss 0.56, Acc 0.7\n",
      "Step 18, Epoch 0 Metrics [array([0.57464874], dtype=float32), array([0.7265625], dtype=float32)]\n",
      "Step 19, Test Loss 0.54, Acc 0.76\n",
      "Step 19, Epoch 0 Metrics [array([0.52074516], dtype=float32), array([0.7578125], dtype=float32)]\n",
      "Step 20, Test Loss 0.53, Acc 0.75\n",
      "Step 20, Epoch 0 Metrics [array([0.5255684], dtype=float32), array([0.7734375], dtype=float32)]\n",
      "Step 21, Test Loss 0.54, Acc 0.74\n",
      "Step 21, Epoch 0 Metrics [array([0.53034353], dtype=float32), array([0.734375], dtype=float32)]\n",
      "Step 22, Test Loss 0.54, Acc 0.72\n",
      "Step 22, Epoch 0 Metrics [array([0.55724704], dtype=float32), array([0.7265625], dtype=float32)]\n",
      "Step 23, Test Loss 0.54, Acc 0.73\n",
      "Step 23, Epoch 0 Metrics [array([0.60450304], dtype=float32), array([0.6796875], dtype=float32)]\n",
      "Step 24, Test Loss 0.49, Acc 0.8\n",
      "Step 24, Epoch 0 Metrics [array([0.5393014], dtype=float32), array([0.75], dtype=float32)]\n",
      "Step 25, Test Loss 0.47, Acc 0.82\n",
      "Step 25, Epoch 0 Metrics [array([0.4819855], dtype=float32), array([0.8125], dtype=float32)]\n",
      "Step 26, Test Loss 0.47, Acc 0.8\n",
      "Step 26, Epoch 0 Metrics [array([0.455698], dtype=float32), array([0.8125], dtype=float32)]\n",
      "Step 27, Test Loss 0.47, Acc 0.8\n",
      "Step 27, Epoch 0 Metrics [array([0.46263516], dtype=float32), array([0.7734375], dtype=float32)]\n",
      "Step 28, Test Loss 0.46, Acc 0.81\n",
      "Step 28, Epoch 0 Metrics [array([0.4480282], dtype=float32), array([0.8125], dtype=float32)]\n",
      "Step 29, Test Loss 0.44, Acc 0.83\n",
      "Step 29, Epoch 0 Metrics [array([0.47295645], dtype=float32), array([0.75], dtype=float32)]\n",
      "Step 30, Test Loss 0.44, Acc 0.83\n",
      "Step 30, Epoch 0 Metrics [array([0.39714667], dtype=float32), array([0.9140625], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "train_loop(fluid.default_main_program())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'use_cuda' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-383b70fae28a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCUDAPlace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCPUPlace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mexe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minference_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'use_cuda' is not defined"
     ]
    }
   ],
   "source": [
    "place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\n",
    "exe = fluid.Executor(place)\n",
    "inference_scope = fluid.core.Scope()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-139b10257bdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreviews_str\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mUNK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<unk>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mlod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_dict' is not defined"
     ]
    }
   ],
   "source": [
    "reviews_str = [\n",
    "    'It would be stupid to not watch this', 'this is a great movie', 'this is very bad'\n",
    "]\n",
    "reviews = [c.split() for c in reviews_str]\n",
    "\n",
    "UNK = word_dict['<unk>']\n",
    "lod = []\n",
    "for c in reviews:\n",
    "    lod.append([word_dict.get(words, UNK) for words in c])\n",
    "\n",
    "base_shape = [[len(c) for c in lod]]\n",
    "\n",
    "tensor_words = fluid.create_lod_tensor(lod, base_shape, place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict probability of  0.6173885  to be positive and  0.38261148  to be negative for review ' read the book forget the movie '\n",
      "Predict probability of  0.6034464  to be positive and  0.39655355  to be negative for review ' this is a great movie '\n",
      "Predict probability of  0.58729345  to be positive and  0.41270655  to be negative for review ' this is very bad '\n"
     ]
    }
   ],
   "source": [
    "with fluid.scope_guard(inference_scope):\n",
    "\n",
    "    [inferencer, feed_target_names,\n",
    "     fetch_targets] = fluid.io.load_inference_model(params_dirname, exe)\n",
    "\n",
    "    assert feed_target_names[0] == \"words\"\n",
    "    results = exe.run(inferencer,\n",
    "                      feed={feed_target_names[0]: tensor_words},\n",
    "                      fetch_list=fetch_targets,\n",
    "                      return_numpy=False)\n",
    "    np_data = np.array(results[0])\n",
    "    for i, r in enumerate(np_data):\n",
    "        print(\"Predict probability of \", r[0], \" to be positive and \", r[1],\n",
    "              \" to be negative for review \\'\", reviews_str[i], \"\\'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural networks excel at learning the spatial structure in input data.\n",
    "\n",
    "# The IMDB review data does have a one-dimensional spatial structure in the sequence of words in reviews and the CNN may be able to pick out invariant features for good and bad sentiment. This learned spatial features may then be learned as sequences by an LSTM layer.\n",
    "\n",
    "# We can easily add a one-dimensional CNN and max pooling layers after the Embedding layer which then feed the consolidated features to the LSTM. We can use a smallish set of 32 features with a small filter length of 3. The pooling layer can use the standard length of 2 to halve the feature map size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
